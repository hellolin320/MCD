{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-27T14:10:35.526363Z",
     "iopub.status.busy": "2024-03-27T14:10:35.525285Z",
     "iopub.status.idle": "2024-03-27T14:10:35.532026Z",
     "shell.execute_reply": "2024-03-27T14:10:35.530914Z",
     "shell.execute_reply.started": "2024-03-27T14:10:35.526320Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.7.4 (default, Aug 13 2019, 20:35:49) \r\n",
      "[GCC 7.3.0]\r\n"
     ]
    }
   ],
   "source": [
    "# 查看版本信息\n",
    "import sys\n",
    "print(sys.version)\n",
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T12:51:39.369552Z",
     "iopub.status.busy": "2024-04-07T12:51:39.368881Z",
     "iopub.status.idle": "2024-04-07T12:51:41.327314Z",
     "shell.execute_reply": "2024-04-07T12:51:41.326011Z",
     "shell.execute_reply.started": "2024-04-07T12:51:39.369515Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                        Version\r\n",
      "------------------------------ ---------------\r\n",
      "absl-py                        0.8.1\r\n",
      "aiofiles                       23.2.1\r\n",
      "aiohttp                        3.8.3\r\n",
      "aiosignal                      1.3.1\r\n",
      "alembic                        1.8.1\r\n",
      "altair                         4.2.0\r\n",
      "annotated-types                0.5.0\r\n",
      "anyio                          3.7.1\r\n",
      "argon2-cffi                    21.3.0\r\n",
      "argon2-cffi-bindings           21.2.0\r\n",
      "aspy.yaml                      1.3.0\r\n",
      "astor                          0.8.1\r\n",
      "astroid                        2.4.1\r\n",
      "async-generator                1.10\r\n",
      "async-timeout                  4.0.2\r\n",
      "asynctest                      0.13.0\r\n",
      "attrs                          22.1.0\r\n",
      "audioread                      2.1.8\r\n",
      "autopep8                       1.6.0\r\n",
      "Babel                          2.8.0\r\n",
      "backcall                       0.1.0\r\n",
      "backports.zoneinfo             0.2.1\r\n",
      "bce-python-sdk                 0.8.53\r\n",
      "beautifulsoup4                 4.11.1\r\n",
      "bleach                         5.0.1\r\n",
      "blinker                        1.5\r\n",
      "cachetools                     4.0.0\r\n",
      "certifi                        2019.9.11\r\n",
      "certipy                        0.1.3\r\n",
      "cffi                           1.15.1\r\n",
      "cfgv                           2.0.1\r\n",
      "chardet                        3.0.4\r\n",
      "charset-normalizer             2.1.1\r\n",
      "click                          8.0.4\r\n",
      "cloudpickle                    1.6.0\r\n",
      "cma                            2.7.0\r\n",
      "colorama                       0.4.4\r\n",
      "colorlog                       4.1.0\r\n",
      "commonmark                     0.9.1\r\n",
      "cryptography                   38.0.1\r\n",
      "cycler                         0.10.0\r\n",
      "Cython                         0.29\r\n",
      "datasets                       2.7.1\r\n",
      "debugpy                        1.6.0\r\n",
      "decorator                      4.4.2\r\n",
      "defusedxml                     0.7.1\r\n",
      "dill                           0.3.3\r\n",
      "easydict                       1.9\r\n",
      "entrypoints                    0.4\r\n",
      "et-xmlfile                     1.0.1\r\n",
      "exceptiongroup                 1.2.0\r\n",
      "fastapi                        0.85.1\r\n",
      "fastjsonschema                 2.16.1\r\n",
      "ffmpy                          0.3.1\r\n",
      "filelock                       3.0.12\r\n",
      "fire                           0.5.0\r\n",
      "flake8                         4.0.1\r\n",
      "Flask                          1.1.1\r\n",
      "Flask-Babel                    1.0.0\r\n",
      "Flask-Cors                     3.0.8\r\n",
      "forbiddenfruit                 0.1.3\r\n",
      "frozenlist                     1.3.3\r\n",
      "fsspec                         2022.11.0\r\n",
      "funcsigs                       1.0.2\r\n",
      "future                         0.18.0\r\n",
      "gast                           0.3.3\r\n",
      "gitdb                          4.0.5\r\n",
      "GitPython                      3.1.14\r\n",
      "google-auth                    1.10.0\r\n",
      "google-auth-oauthlib           0.4.1\r\n",
      "gradio                         3.34.0\r\n",
      "gradio_client                  0.2.6\r\n",
      "graphviz                       0.13\r\n",
      "greenlet                       1.1.3\r\n",
      "grpcio                         1.35.0\r\n",
      "gunicorn                       20.0.4\r\n",
      "gym                            0.12.1\r\n",
      "h11                            0.14.0\r\n",
      "h5py                           2.9.0\r\n",
      "httpcore                       0.17.3\r\n",
      "httpx                          0.24.1\r\n",
      "huggingface-hub                0.16.4\r\n",
      "identify                       1.4.10\r\n",
      "idna                           2.8\r\n",
      "imageio                        2.6.1\r\n",
      "imageio-ffmpeg                 0.3.0\r\n",
      "importlib-metadata             4.2.0\r\n",
      "importlib-resources            5.9.0\r\n",
      "ipykernel                      6.9.1\r\n",
      "ipython                        7.34.0\r\n",
      "ipython-genutils               0.2.0\r\n",
      "ipywidgets                     7.6.5\r\n",
      "isort                          4.3.21\r\n",
      "itsdangerous                   1.1.0\r\n",
      "jdcal                          1.4.1\r\n",
      "jedi                           0.17.2\r\n",
      "jieba                          0.42.1\r\n",
      "Jinja2                         3.0.0\r\n",
      "joblib                         0.14.1\r\n",
      "JPype1                         0.7.2\r\n",
      "json5                          0.9.5\r\n",
      "jsonschema                     4.16.0\r\n",
      "jupyter-archive                3.2.1\r\n",
      "jupyter_client                 7.3.5\r\n",
      "jupyter-core                   4.11.1\r\n",
      "jupyter-lsp                    1.5.1\r\n",
      "jupyter-server                 1.16.0\r\n",
      "jupyter-telemetry              0.1.0\r\n",
      "jupyterhub                     1.3.0\r\n",
      "jupyterlab                     3.4.5\r\n",
      "jupyterlab-language-pack-zh-CN 3.4.post1\r\n",
      "jupyterlab-pygments            0.2.2\r\n",
      "jupyterlab-server              2.10.3\r\n",
      "jupyterlab-widgets             3.0.3\r\n",
      "kiwisolver                     1.1.0\r\n",
      "lazy-object-proxy              1.4.3\r\n",
      "librosa                        0.7.2\r\n",
      "lightgbm                       3.1.1\r\n",
      "linkify-it-py                  2.0.2\r\n",
      "llvmlite                       0.31.0\r\n",
      "lxml                           4.9.1\r\n",
      "Mako                           1.2.2\r\n",
      "Markdown                       3.1.1\r\n",
      "markdown-it-py                 2.2.0\r\n",
      "MarkupSafe                     2.0.1\r\n",
      "matplotlib                     2.2.3\r\n",
      "matplotlib-inline              0.1.6\r\n",
      "mccabe                         0.6.1\r\n",
      "mdit-py-plugins                0.3.3\r\n",
      "mdurl                          0.1.1\r\n",
      "mistune                        0.8.4\r\n",
      "more-itertools                 7.2.0\r\n",
      "moviepy                        1.0.1\r\n",
      "multidict                      6.0.2\r\n",
      "multiprocess                   0.70.11.1\r\n",
      "nbclassic                      0.3.1\r\n",
      "nbclient                       0.5.13\r\n",
      "nbconvert                      6.4.4\r\n",
      "nbformat                       5.5.0\r\n",
      "nest-asyncio                   1.5.5\r\n",
      "netifaces                      0.10.9\r\n",
      "networkx                       2.4\r\n",
      "nltk                           3.4.5\r\n",
      "nodeenv                        1.3.4\r\n",
      "notebook                       5.7.8\r\n",
      "numba                          0.48.0\r\n",
      "numpy                          1.19.5\r\n",
      "oauthlib                       3.1.0\r\n",
      "objgraph                       3.4.1\r\n",
      "opencv-python                  4.6.0.66\r\n",
      "openpyxl                       3.0.5\r\n",
      "opt-einsum                     3.3.0\r\n",
      "orjson                         3.9.7\r\n",
      "packaging                      21.3\r\n",
      "paddle-bfloat                  0.1.7\r\n",
      "paddle2onnx                    1.0.0\r\n",
      "paddlefsl                      1.1.0\r\n",
      "paddlehub                      2.3.0\r\n",
      "paddlenlp                      2.4.2\r\n",
      "paddlepaddle                   2.4.0\r\n",
      "pamela                         1.0.0\r\n",
      "pandas                         1.1.5\r\n",
      "pandocfilters                  1.5.0\r\n",
      "parl                           1.4.1\r\n",
      "parso                          0.7.1\r\n",
      "pathlib                        1.0.1\r\n",
      "pexpect                        4.7.0\r\n",
      "pickleshare                    0.7.5\r\n",
      "Pillow                         8.2.0\r\n",
      "pip                            22.1.2\r\n",
      "pkgutil_resolve_name           1.3.10\r\n",
      "plotly                         5.8.0\r\n",
      "pluggy                         1.0.0\r\n",
      "pre-commit                     1.21.0\r\n",
      "prettytable                    0.7.2\r\n",
      "proglog                        0.1.9\r\n",
      "prometheus-client              0.14.1\r\n",
      "prompt-toolkit                 2.0.10\r\n",
      "protobuf                       3.20.0\r\n",
      "psutil                         5.7.2\r\n",
      "ptyprocess                     0.7.0\r\n",
      "py4j                           0.10.9.2\r\n",
      "pyarrow                        10.0.0\r\n",
      "pyasn1                         0.4.8\r\n",
      "pyasn1-modules                 0.2.7\r\n",
      "pybboxes                       0.1.1\r\n",
      "pycodestyle                    2.8.0\r\n",
      "pycparser                      2.21\r\n",
      "pycryptodome                   3.9.9\r\n",
      "pydantic                       1.10.13\r\n",
      "pydantic_core                  2.14.6\r\n",
      "pydeck                         0.8.0\r\n",
      "pydocstyle                     5.0.2\r\n",
      "pydub                          0.25.1\r\n",
      "pyflakes                       2.4.0\r\n",
      "pyglet                         1.4.5\r\n",
      "Pygments                       2.13.0\r\n",
      "pyhumps                        3.8.0\r\n",
      "pylint                         2.5.2\r\n",
      "Pympler                        1.0.1\r\n",
      "pynvml                         8.0.4\r\n",
      "pyOpenSSL                      22.0.0\r\n",
      "pyparsing                      3.0.9\r\n",
      "pypmml                         0.9.11\r\n",
      "pyrsistent                     0.18.1\r\n",
      "python-dateutil                2.8.2\r\n",
      "python-json-logger             2.0.4\r\n",
      "python-jsonrpc-server          0.3.4\r\n",
      "python-language-server         0.33.0\r\n",
      "python-lsp-jsonrpc             1.0.0\r\n",
      "python-lsp-server              1.5.0\r\n",
      "python-multipart               0.0.6\r\n",
      "pytz                           2019.3\r\n",
      "pytz-deprecation-shim          0.1.0.post0\r\n",
      "PyYAML                         5.1.2\r\n",
      "pyzmq                          23.2.1\r\n",
      "rarfile                        3.1\r\n",
      "recordio                       0.1.7\r\n",
      "requests                       2.24.0\r\n",
      "requests-oauthlib              1.3.0\r\n",
      "resampy                        0.2.2\r\n",
      "responses                      0.18.0\r\n",
      "rich                           12.6.0\r\n",
      "rope                           0.17.0\r\n",
      "rsa                            4.0\r\n",
      "ruamel.yaml                    0.17.21\r\n",
      "ruamel.yaml.clib               0.2.6\r\n",
      "sahi                           0.10.1\r\n",
      "scikit-learn                   0.22.1\r\n",
      "scipy                          1.3.0\r\n",
      "seaborn                        0.10.0\r\n",
      "semantic-version               2.10.0\r\n",
      "semver                         2.13.0\r\n",
      "Send2Trash                     1.8.0\r\n",
      "sentencepiece                  0.1.96\r\n",
      "seqeval                        1.2.2\r\n",
      "setuptools                     41.4.0\r\n",
      "shapely                        2.0.0\r\n",
      "shellcheck-py                  0.7.1.1\r\n",
      "six                            1.16.0\r\n",
      "sklearn                        0.0\r\n",
      "smmap                          3.0.5\r\n",
      "sniffio                        1.3.0\r\n",
      "snowballstemmer                2.0.0\r\n",
      "SoundFile                      0.10.3.post1\r\n",
      "soupsieve                      2.3.2.post1\r\n",
      "SQLAlchemy                     1.4.41\r\n",
      "starlette                      0.20.4\r\n",
      "streamlit                      1.13.0\r\n",
      "streamlit-image-comparison     0.0.3\r\n",
      "tabulate                       0.8.3\r\n",
      "tb-nightly                     1.15.0a20190801\r\n",
      "tb-paddle                      0.3.6\r\n",
      "tenacity                       8.0.1\r\n",
      "tensorboard                    2.1.0\r\n",
      "tensorboardX                   1.8\r\n",
      "termcolor                      1.1.0\r\n",
      "terminado                      0.15.0\r\n",
      "terminaltables                 3.1.10\r\n",
      "testpath                       0.4.2\r\n",
      "tinycss2                       1.1.1\r\n",
      "toml                           0.10.0\r\n",
      "toolz                          0.12.0\r\n",
      "tornado                        6.2\r\n",
      "tqdm                           4.64.1\r\n",
      "traitlets                      5.4.0\r\n",
      "typed-ast                      1.4.1\r\n",
      "typing_extensions              4.7.1\r\n",
      "tzdata                         2022.7\r\n",
      "tzlocal                        4.2\r\n",
      "uc-micro-py                    1.0.2\r\n",
      "ujson                          1.35\r\n",
      "urllib3                        1.25.11\r\n",
      "uvicorn                        0.22.0\r\n",
      "validators                     0.20.0\r\n",
      "virtualenv                     16.7.9\r\n",
      "visualdl                       2.4.0\r\n",
      "watchdog                       2.2.0\r\n",
      "wcwidth                        0.1.7\r\n",
      "webencodings                   0.5.1\r\n",
      "websocket-client               1.4.1\r\n",
      "websockets                     11.0.3\r\n",
      "Werkzeug                       0.16.0\r\n",
      "whatthepatch                   1.0.2\r\n",
      "wheel                          0.33.6\r\n",
      "widgetsnbextension             3.5.2\r\n",
      "wrapt                          1.12.1\r\n",
      "xarray                         0.16.2\r\n",
      "xgboost                        1.3.3\r\n",
      "xlrd                           1.2.0\r\n",
      "xxhash                         3.1.0\r\n",
      "yapf                           0.26.0\r\n",
      "yarl                           1.7.2\r\n",
      "zipp                           3.8.1\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.1.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.0\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\r\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-27T14:10:37.166405Z",
     "iopub.status.busy": "2024-03-27T14:10:37.165367Z",
     "iopub.status.idle": "2024-03-27T14:10:41.069564Z",
     "shell.execute_reply": "2024-03-27T14:10:41.068247Z",
     "shell.execute_reply.started": "2024-03-27T14:10:37.166366Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import paddle\n",
    "import paddlenlp\n",
    "from paddle.io import Dataset\n",
    "from paddlenlp.datasets import load_dataset,MapDataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:10:42.363648Z",
     "iopub.status.busy": "2024-03-27T14:10:42.363053Z",
     "iopub.status.idle": "2024-03-27T14:10:44.863182Z",
     "shell.execute_reply": "2024-03-27T14:10:44.861987Z",
     "shell.execute_reply.started": "2024-03-27T14:10:42.363608Z"
    },
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 训练类\n",
    "class MyTrainDataset(Dataset):\n",
    "    def __init__(self, file):\n",
    "        def read_train(file):\n",
    "            \"\"\"Reads data\"\"\"\n",
    "            f = pd.read_csv(file, sep=\"\\t\")\n",
    "            head = None\n",
    "            for index, row in f.iterrows():\n",
    "                text = row.get('text_a')\n",
    "                label = row.get('label')\n",
    "                if text is not None and label is not None:\n",
    "                    yield {\"text\": text, \"label\": label, \"qid\": ''}\n",
    "        self.data = list(read_train(file))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [\"0\", \"1\", \"2\"]\n",
    "\n",
    "train = MyTrainDataset('data/train.csv')\n",
    "train_ds = MapDataset(train,label_list=train.get_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:10:46.509514Z",
     "iopub.status.busy": "2024-03-27T14:10:46.508870Z",
     "iopub.status.idle": "2024-03-27T14:10:46.818930Z",
     "shell.execute_reply": "2024-03-27T14:10:46.818008Z",
     "shell.execute_reply.started": "2024-03-27T14:10:46.509475Z"
    },
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 开发类\n",
    "class MyDevDataset(Dataset):\n",
    "    def __init__(self, file):\n",
    "        def read_dev(file):\n",
    "            \"\"\"Reads data\"\"\"\n",
    "            f = pd.read_csv(file, sep=\"\\t\")\n",
    "            head = None\n",
    "            for index, row in f.iterrows():\n",
    "                text = row.get('text_a')\n",
    "                label = row.get('label')\n",
    "                qid = row.get('qid')\n",
    "                if text is not None and label is not None and qid is not None:\n",
    "                    yield {\"text\": text, \"label\": label, \"qid\": qid}\n",
    "        self.data = list(read_dev(file))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [\"0\", \"1\", \"2\"]\n",
    "\n",
    "dev = MyDevDataset('data/dev.csv')\n",
    "dev_ds = MapDataset(dev,label_list=dev.get_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:10:48.362176Z",
     "iopub.status.busy": "2024-03-27T14:10:48.361426Z",
     "iopub.status.idle": "2024-03-27T14:10:48.699015Z",
     "shell.execute_reply": "2024-03-27T14:10:48.697977Z",
     "shell.execute_reply.started": "2024-03-27T14:10:48.362135Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 测试类\n",
    "class MyTestDataset(Dataset):\n",
    "    def __init__(self, file):\n",
    "        def read_test(file):\n",
    "            \"\"\"Reads data\"\"\"\n",
    "            f = pd.read_csv(file, sep=\"\\t\")\n",
    "            head = None\n",
    "            for index, row in f.iterrows():\n",
    "                text = row.get('text_a')\n",
    "                qid = row.get('qid')\n",
    "                if text is not None and qid is not None:\n",
    "                    yield {\"text\": text, \"label\": '', \"qid\": qid}\n",
    "        self.data = list(read_test(file))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_labels(self):\n",
    "        return [\"0\", \"1\", \"2\"]\n",
    "\n",
    "test = MyTestDataset('data/test.csv')\n",
    "test_ds = MapDataset(test,label_list=test.get_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-27T12:50:47.161205Z",
     "iopub.status.busy": "2024-03-27T12:50:47.160644Z",
     "iopub.status.idle": "2024-03-27T12:50:49.953012Z",
     "shell.execute_reply": "2024-03-27T12:50:49.952231Z",
     "shell.execute_reply.started": "2024-03-27T12:50:47.161171Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'paddlenlp.datasets.dataset.MapDataset'>\r\n",
      "<class 'paddlenlp.datasets.dataset.MapDataset'>\r\n",
      "<class 'paddlenlp.datasets.dataset.MapDataset'>\r\n"
     ]
    }
   ],
   "source": [
    "#加载数据集,弃用\n",
    "# from paddle.io import Dataset\n",
    "# from paddlenlp.datasets import load_dataset,MapDataset\n",
    "# import pandas as pd\n",
    "\n",
    "# def read_train(filename):\n",
    "#     \"\"\"Reads data\"\"\"\n",
    "#     f = pd.read_csv(filename, sep=\"\\t\")\n",
    "#     head = None\n",
    "#     for index, row in f.iterrows():\n",
    "#         text = row.get('text_a')\n",
    "#         label = row.get('label')\n",
    "#         if text is not None and label is not None:\n",
    "#             yield {\"text\": text, \"label\": label, \"qid\": ''}\n",
    "\n",
    "# def read_dev(filename):\n",
    "#     \"\"\"Reads data\"\"\"\n",
    "#     f=pd.read_csv(filename,sep=\"\\t\")\n",
    "#     head = None\n",
    "#     for index, row in f.iterrows():\n",
    "#         text = row.get('text_a')\n",
    "#         label = row.get('label')\n",
    "#         qid = row.get('qid')\n",
    "#         if text is not None and label is not None and qid is not None:\n",
    "#             yield {\"text\": text, \"label\": label, \"qid\": qid}\n",
    "\n",
    "# def read_test(filename):\n",
    "#     \"\"\"Reads data\"\"\"\n",
    "#     f=pd.read_csv(filename,sep=\"\\t\")\n",
    "#     head = None\n",
    "#     for index, row in f.iterrows():\n",
    "#         text = row.get('text_a')\n",
    "#         qid = row.get('qid')\n",
    "#         if text is not None and qid is not None:\n",
    "#             yield {\"text\": text, \"label\": '', \"qid\": qid}\n",
    "\n",
    "\n",
    "# # 使用你的 read 函数读取数据\n",
    "# train = list(read_train(\"data/train.csv\"))\n",
    "# dev = list(read_dev(\"data/dev.csv\"))\n",
    "# test = list(read_test(\"data/test.csv\"))\n",
    "\n",
    "# # 创建数据集对象\n",
    "# train_ds = MapDataset(train)\n",
    "# dev_ds = MapDataset(dev)\n",
    "# test_ds = MapDataset(test)\n",
    "\n",
    "# print(type(train_ds))\n",
    "# print(type(dev_ds))\n",
    "# print(type(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-03-27T14:10:52.057986Z",
     "iopub.status.busy": "2024-03-27T14:10:52.057299Z",
     "iopub.status.idle": "2024-03-27T14:10:52.129020Z",
     "shell.execute_reply": "2024-03-27T14:10:52.121012Z",
     "shell.execute_reply.started": "2024-03-27T14:10:52.057945Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据类型: <class 'paddlenlp.datasets.dataset.MapDataset'>\r\n",
      "训练集样例: {'text': '今早来吃个早餐，体验很差！图片的炒蛋很少，而且放很久，面包是不怎么热的，跟平时吃得不一样颜色，那块鸡肉好黑的样子！拿餐后发现好多餐盘没有收拾，无从下坐，叫经理换鸡蛋就真的换了鸡蛋，而且餐里面加了油条，油条感觉不是新鲜炸的不怎么热，像放很久，只有薯饼是热和脆！唉', 'label': 2, 'qid': ''}\r\n",
      "验证集样例: {'text': '位置十分好，就在出站口，服务态度也非常不错，还是挺推荐的', 'label': 0, 'qid': 0}\r\n",
      "测试集样例: {'text': '今日Mc Cafe 免费赠饮拿铁，好多人，排队排长龙，龙尾差唔多去到手扶电梯口，睇来大家都好眼训 虽然人好多，但冲咖啡既姐姐一d都唔马虎，奶泡刚打出来继续系噔一噔，慢慢拉花式撞入咖啡，绝对无因为人多而求其贪快，赞！', 'label': '', 'qid': 0}\r\n"
     ]
    }
   ],
   "source": [
    "# 数据集返回为MapDataset类型，查看数据样本详情\n",
    "print(\"数据类型:\", type(train_ds))\n",
    "# label代表标签，qid代表数据编号，测试集中不包含标签信息\n",
    "print(\"训练集样例:\", train_ds[0])\n",
    "print(\"验证集样例:\", dev_ds[0])\n",
    "print(\"测试集样例:\", test_ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:11:02.061748Z",
     "iopub.status.busy": "2024-03-27T14:11:02.060773Z",
     "iopub.status.idle": "2024-03-27T14:11:14.056884Z",
     "shell.execute_reply": "2024-03-27T14:11:14.055795Z",
     "shell.execute_reply.started": "2024-03-27T14:11:02.061702Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-27 22:11:02,064] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.modeling.ErnieForSequenceClassification'> to load 'ernie-3.0-medium-zh'.\r\n",
      "[2024-03-27 22:11:02,068] [    INFO] - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh.pdparams and saved to /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh\r\n",
      "[2024-03-27 22:11:02,071] [    INFO] - Downloading ernie_3.0_medium_zh.pdparams from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh.pdparams\r\n",
      "100%|██████████| 313M/313M [00:08<00:00, 38.9MB/s] \r\n",
      "W0327 22:11:10.612514   173 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 12.0, Runtime API Version: 11.2\r\n",
      "W0327 22:11:10.618561   173 gpu_resources.cc:91] device: 0, cuDNN Version: 8.2.\r\n",
      "[2024-03-27 22:11:13,908] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'ernie-3.0-medium-zh'.\r\n",
      "[2024-03-27 22:11:13,912] [    INFO] - Downloading https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh_vocab.txt and saved to /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh\r\n",
      "[2024-03-27 22:11:13,915] [    INFO] - Downloading ernie_3.0_medium_zh_vocab.txt from https://bj.bcebos.com/paddlenlp/models/transformers/ernie_3.0/ernie_3.0_medium_zh_vocab.txt\r\n",
      "100%|██████████| 182k/182k [00:00<00:00, 10.1MB/s]\r\n",
      "[2024-03-27 22:11:14,047] [    INFO] - tokenizer config file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/tokenizer_config.json\r\n",
      "[2024-03-27 22:11:14,050] [    INFO] - Special tokens file saved in /home/aistudio/.paddlenlp/models/ernie-3.0-medium-zh/special_tokens_map.json\r\n"
     ]
    }
   ],
   "source": [
    "from paddlenlp.transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "#定义\"ernie-3.0-medium-zh\"模型\n",
    "model_name = \"ernie-3.0-medium-zh\"\n",
    "\n",
    "#加载预训练模型，并指定分类的类别数为训练集的标签数量\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_classes=len(train_ds.label_list))\n",
    "\n",
    "#加载预训练模型对应的分词器。\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:11:27.603389Z",
     "iopub.status.busy": "2024-03-27T14:11:27.602548Z",
     "iopub.status.idle": "2024-03-27T14:11:27.611635Z",
     "shell.execute_reply": "2024-03-27T14:11:27.610689Z",
     "shell.execute_reply.started": "2024-03-27T14:11:27.603355Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "from paddle.io import DataLoader, BatchSampler\n",
    "from paddlenlp.data import DataCollatorWithPadding\n",
    "\n",
    "# 数据预处理函数，利用分词器将文本转化为整数序列\n",
    "# examples：输入的数据样本，通常是一个字典，包含了文本数据和对应的标签。\n",
    "# tokenizer：分词器，用于将文本数据转换为模型可以接受的格式。\n",
    "# max_seq_length：序列的最大长度，超过这个长度的序列将被截断。\n",
    "# is_test：一个布尔值，表示当前是否为测试模式。\n",
    "def preprocess_function(examples, tokenizer, max_seq_length, is_test=False):\n",
    "\n",
    "    # 使用分词器tokenizer对输入的文本examples[\"text\"]进行处理，得到的结果保存在result中。\n",
    "    result = tokenizer(text=examples[\"text\"], max_seq_len=max_seq_length)\n",
    "\n",
    "    # 如果当前不是测试模式（is_test=False），那么将输入数据的标签examples[\"label\"]添加到result中\n",
    "    if not is_test:\n",
    "        result[\"labels\"] = examples[\"label\"]\n",
    "    return result\n",
    "\n",
    "# 这个函数等同于调用preprocess_function\n",
    "trans_func = functools.partial(preprocess_function, tokenizer=tokenizer, max_seq_length=128)\n",
    "# 这两行代码将trans_func函数应用到训练集和开发集的每个样本上。\n",
    "# 这意味着每个样本都会被分词，序列长度会被限制在128以内，如果不是测试模式，还会添加标签。\n",
    "train_ds = train_ds.map(trans_func)\n",
    "dev_ds = dev_ds.map(trans_func)\n",
    "\n",
    "# collate_fn函数构造，将不同长度序列充到批中数据的最大长度，再将数据堆叠\n",
    "collate_fn = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# 定义BatchSampler，选择批大小和是否随机乱序，进行DataLoader\n",
    "# 这两行代码定义了批量采样器（BatchSampler）。批量采样器用于从数据集中选择批量的数据。\n",
    "# 对于训练集，批大小被设置为32，数据会被随机打乱；对于开发集，批大小被设置为64，数据不会被打乱。\n",
    "train_batch_sampler = BatchSampler(train_ds, batch_size=32, shuffle=True)\n",
    "dev_batch_sampler = BatchSampler(dev_ds, batch_size=64, shuffle=False)\n",
    "# 这两行代码创建了数据加载器。数据加载器用于在训练和评估模型时批量加载数据。\n",
    "train_data_loader = DataLoader(dataset=train_ds, batch_sampler=train_batch_sampler, collate_fn=collate_fn)\n",
    "dev_data_loader = DataLoader(dataset=dev_ds, batch_sampler=dev_batch_sampler, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:11:37.498420Z",
     "iopub.status.busy": "2024-03-27T14:11:37.497341Z",
     "iopub.status.idle": "2024-03-27T14:11:37.503863Z",
     "shell.execute_reply": "2024-03-27T14:11:37.503106Z",
     "shell.execute_reply.started": "2024-03-27T14:11:37.498378Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Adam优化器、交叉熵损失函数、accuracy评价指标\n",
    "# 创建了一个AdamW优化器，用于优化模型的参数。这里的学习率设置为2e-5，优化的参数是模型的参数\n",
    "optimizer = paddle.optimizer.AdamW(learning_rate=2e-5, parameters=model.parameters())\n",
    "# 这行代码定义了交叉熵损失函数，这是一种常用的分类任务的损失函数\n",
    "criterion = paddle.nn.loss.CrossEntropyLoss()\n",
    "# 定义了准确率作为评估指标，用于评估模型的性能\n",
    "metric = paddle.metric.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:11:58.782212Z",
     "iopub.status.busy": "2024-03-27T14:11:58.780880Z",
     "iopub.status.idle": "2024-03-27T14:25:43.329134Z",
     "shell.execute_reply": "2024-03-27T14:25:43.328161Z",
     "shell.execute_reply.started": "2024-03-27T14:11:58.782163Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 10, epoch: 1, batch: 10, loss: 0.80555, accu: 0.53438, speed: 4.72 step/s\r\n",
      "global step 20, epoch: 1, batch: 20, loss: 0.84935, accu: 0.55937, speed: 9.78 step/s\r\n",
      "global step 30, epoch: 1, batch: 30, loss: 0.70245, accu: 0.59271, speed: 9.81 step/s\r\n",
      "global step 40, epoch: 1, batch: 40, loss: 0.87151, accu: 0.62109, speed: 9.73 step/s\r\n",
      "global step 50, epoch: 1, batch: 50, loss: 0.52292, accu: 0.64625, speed: 9.74 step/s\r\n",
      "global step 60, epoch: 1, batch: 60, loss: 0.61718, accu: 0.65781, speed: 9.73 step/s\r\n",
      "global step 70, epoch: 1, batch: 70, loss: 0.66179, accu: 0.66071, speed: 9.65 step/s\r\n",
      "global step 80, epoch: 1, batch: 80, loss: 0.63690, accu: 0.67109, speed: 9.74 step/s\r\n",
      "global step 90, epoch: 1, batch: 90, loss: 0.43375, accu: 0.68021, speed: 9.63 step/s\r\n",
      "global step 100, epoch: 1, batch: 100, loss: 0.48800, accu: 0.69000, speed: 9.54 step/s\r\n",
      "100 eval loss: 0.60693, accuracy: 0.72490\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-27 22:12:18,701] [    INFO] - tokenizer config file saved in new_ernie_ckpt/tokenizer_config.json\r\n",
      "[2024-03-27 22:12:18,706] [    INFO] - Special tokens file saved in new_ernie_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 110, epoch: 1, batch: 110, loss: 0.61144, accu: 0.75000, speed: 1.05 step/s\r\n",
      "global step 120, epoch: 1, batch: 120, loss: 0.49467, accu: 0.74375, speed: 9.55 step/s\r\n",
      "global step 130, epoch: 1, batch: 130, loss: 0.62742, accu: 0.74479, speed: 9.36 step/s\r\n",
      "global step 140, epoch: 1, batch: 140, loss: 0.53298, accu: 0.75391, speed: 9.03 step/s\r\n",
      "global step 150, epoch: 1, batch: 150, loss: 0.59486, accu: 0.74562, speed: 8.64 step/s\r\n",
      "global step 160, epoch: 1, batch: 160, loss: 0.63068, accu: 0.73906, speed: 9.69 step/s\r\n",
      "global step 170, epoch: 1, batch: 170, loss: 0.60973, accu: 0.73438, speed: 9.00 step/s\r\n",
      "global step 180, epoch: 1, batch: 180, loss: 0.67303, accu: 0.73984, speed: 9.50 step/s\r\n",
      "global step 190, epoch: 1, batch: 190, loss: 0.65287, accu: 0.73438, speed: 9.70 step/s\r\n",
      "global step 200, epoch: 1, batch: 200, loss: 0.68225, accu: 0.73188, speed: 9.57 step/s\r\n",
      "200 eval loss: 0.61182, accuracy: 0.73752\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-27 22:12:40,465] [    INFO] - tokenizer config file saved in new_ernie_ckpt/tokenizer_config.json\r\n",
      "[2024-03-27 22:12:40,469] [    INFO] - Special tokens file saved in new_ernie_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 210, epoch: 1, batch: 210, loss: 0.80368, accu: 0.76875, speed: 0.83 step/s\r\n",
      "global step 220, epoch: 1, batch: 220, loss: 0.45309, accu: 0.76250, speed: 9.70 step/s\r\n",
      "global step 230, epoch: 1, batch: 230, loss: 0.43064, accu: 0.74167, speed: 9.64 step/s\r\n",
      "global step 240, epoch: 1, batch: 240, loss: 0.56690, accu: 0.73828, speed: 9.68 step/s\r\n",
      "global step 250, epoch: 1, batch: 250, loss: 0.50859, accu: 0.74000, speed: 9.38 step/s\r\n",
      "global step 260, epoch: 1, batch: 260, loss: 0.42541, accu: 0.75156, speed: 9.52 step/s\r\n",
      "global step 270, epoch: 1, batch: 270, loss: 0.64059, accu: 0.74375, speed: 9.62 step/s\r\n",
      "global step 280, epoch: 1, batch: 280, loss: 0.63037, accu: 0.74141, speed: 9.67 step/s\r\n",
      "global step 290, epoch: 1, batch: 290, loss: 0.57337, accu: 0.73993, speed: 9.68 step/s\r\n",
      "global step 300, epoch: 1, batch: 300, loss: 0.56406, accu: 0.74125, speed: 9.64 step/s\r\n",
      "300 eval loss: 0.58541, accuracy: 0.74173\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-27 22:13:01,019] [    INFO] - tokenizer config file saved in new_ernie_ckpt/tokenizer_config.json\r\n",
      "[2024-03-27 22:13:01,025] [    INFO] - Special tokens file saved in new_ernie_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 310, epoch: 1, batch: 310, loss: 0.60524, accu: 0.72813, speed: 0.90 step/s\r\n",
      "global step 320, epoch: 1, batch: 320, loss: 0.53207, accu: 0.75313, speed: 9.22 step/s\r\n",
      "global step 330, epoch: 1, batch: 330, loss: 0.42783, accu: 0.76354, speed: 8.88 step/s\r\n",
      "global step 340, epoch: 1, batch: 340, loss: 0.66071, accu: 0.76250, speed: 9.37 step/s\r\n",
      "global step 350, epoch: 1, batch: 350, loss: 0.87652, accu: 0.75687, speed: 9.56 step/s\r\n",
      "global step 360, epoch: 1, batch: 360, loss: 0.56452, accu: 0.75573, speed: 9.64 step/s\r\n",
      "global step 370, epoch: 1, batch: 370, loss: 0.44123, accu: 0.74911, speed: 9.70 step/s\r\n",
      "global step 380, epoch: 1, batch: 380, loss: 0.79847, accu: 0.74609, speed: 9.30 step/s\r\n",
      "global step 390, epoch: 1, batch: 390, loss: 0.55700, accu: 0.74653, speed: 9.64 step/s\r\n",
      "global step 400, epoch: 1, batch: 400, loss: 0.66884, accu: 0.74344, speed: 9.60 step/s\r\n",
      "400 eval loss: 0.59890, accuracy: 0.73331\r\n",
      "global step 410, epoch: 1, batch: 410, loss: 0.63082, accu: 0.74375, speed: 1.18 step/s\r\n",
      "global step 420, epoch: 1, batch: 420, loss: 0.39817, accu: 0.75156, speed: 9.68 step/s\r\n",
      "global step 430, epoch: 1, batch: 430, loss: 0.50026, accu: 0.76042, speed: 9.71 step/s\r\n",
      "global step 440, epoch: 1, batch: 440, loss: 0.40620, accu: 0.75469, speed: 9.67 step/s\r\n",
      "global step 450, epoch: 1, batch: 450, loss: 0.71672, accu: 0.74625, speed: 9.69 step/s\r\n",
      "global step 460, epoch: 1, batch: 460, loss: 0.58822, accu: 0.74167, speed: 9.63 step/s\r\n",
      "global step 470, epoch: 1, batch: 470, loss: 0.40545, accu: 0.74286, speed: 9.74 step/s\r\n",
      "global step 480, epoch: 1, batch: 480, loss: 0.44152, accu: 0.74531, speed: 9.51 step/s\r\n",
      "global step 490, epoch: 1, batch: 490, loss: 0.79473, accu: 0.74687, speed: 9.70 step/s\r\n",
      "global step 500, epoch: 1, batch: 500, loss: 0.83826, accu: 0.74781, speed: 9.67 step/s\r\n",
      "500 eval loss: 0.57894, accuracy: 0.74678\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-27 22:13:39,407] [    INFO] - tokenizer config file saved in new_ernie_ckpt/tokenizer_config.json\r\n",
      "[2024-03-27 22:13:39,411] [    INFO] - Special tokens file saved in new_ernie_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 510, epoch: 1, batch: 510, loss: 0.78977, accu: 0.72813, speed: 0.91 step/s\r\n",
      "global step 520, epoch: 1, batch: 520, loss: 0.73402, accu: 0.75938, speed: 9.77 step/s\r\n",
      "global step 530, epoch: 1, batch: 530, loss: 0.56888, accu: 0.74687, speed: 9.75 step/s\r\n",
      "global step 540, epoch: 1, batch: 540, loss: 0.53559, accu: 0.75156, speed: 9.59 step/s\r\n",
      "global step 550, epoch: 1, batch: 550, loss: 0.69479, accu: 0.74687, speed: 9.71 step/s\r\n",
      "global step 560, epoch: 1, batch: 560, loss: 0.53815, accu: 0.75156, speed: 9.72 step/s\r\n",
      "global step 570, epoch: 1, batch: 570, loss: 0.34794, accu: 0.74955, speed: 9.73 step/s\r\n",
      "global step 580, epoch: 1, batch: 580, loss: 0.88797, accu: 0.74570, speed: 9.71 step/s\r\n",
      "global step 590, epoch: 1, batch: 590, loss: 0.69268, accu: 0.74201, speed: 9.69 step/s\r\n",
      "global step 600, epoch: 1, batch: 600, loss: 0.51259, accu: 0.73969, speed: 9.70 step/s\r\n",
      "600 eval loss: 0.59219, accuracy: 0.73724\r\n",
      "global step 610, epoch: 1, batch: 610, loss: 0.52638, accu: 0.72500, speed: 1.19 step/s\r\n",
      "global step 620, epoch: 1, batch: 620, loss: 0.63794, accu: 0.74687, speed: 9.73 step/s\r\n",
      "global step 630, epoch: 1, batch: 630, loss: 0.58674, accu: 0.74583, speed: 9.66 step/s\r\n",
      "global step 640, epoch: 1, batch: 640, loss: 0.48443, accu: 0.74531, speed: 9.69 step/s\r\n",
      "global step 650, epoch: 1, batch: 650, loss: 0.84423, accu: 0.74750, speed: 9.61 step/s\r\n",
      "global step 660, epoch: 1, batch: 660, loss: 0.61911, accu: 0.75104, speed: 9.62 step/s\r\n",
      "global step 670, epoch: 1, batch: 670, loss: 0.54798, accu: 0.74821, speed: 9.69 step/s\r\n",
      "global step 680, epoch: 1, batch: 680, loss: 0.80237, accu: 0.74570, speed: 9.69 step/s\r\n",
      "global step 690, epoch: 1, batch: 690, loss: 0.56225, accu: 0.74306, speed: 9.70 step/s\r\n",
      "global step 700, epoch: 1, batch: 700, loss: 0.61638, accu: 0.74062, speed: 9.65 step/s\r\n",
      "700 eval loss: 0.57409, accuracy: 0.75238\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-27 22:14:17,822] [    INFO] - tokenizer config file saved in new_ernie_ckpt/tokenizer_config.json\r\n",
      "[2024-03-27 22:14:17,825] [    INFO] - Special tokens file saved in new_ernie_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 710, epoch: 1, batch: 710, loss: 0.70483, accu: 0.78750, speed: 0.88 step/s\r\n",
      "global step 720, epoch: 1, batch: 720, loss: 0.68173, accu: 0.76875, speed: 9.61 step/s\r\n",
      "global step 730, epoch: 1, batch: 730, loss: 0.69680, accu: 0.75208, speed: 9.68 step/s\r\n",
      "global step 740, epoch: 1, batch: 740, loss: 0.55317, accu: 0.75313, speed: 9.73 step/s\r\n",
      "global step 750, epoch: 1, batch: 750, loss: 0.66447, accu: 0.74500, speed: 9.77 step/s\r\n",
      "global step 760, epoch: 1, batch: 760, loss: 0.52997, accu: 0.73906, speed: 9.72 step/s\r\n",
      "global step 770, epoch: 1, batch: 770, loss: 0.53154, accu: 0.73839, speed: 9.71 step/s\r\n",
      "global step 780, epoch: 1, batch: 780, loss: 0.56154, accu: 0.73945, speed: 9.73 step/s\r\n",
      "global step 790, epoch: 1, batch: 790, loss: 0.75570, accu: 0.73924, speed: 9.66 step/s\r\n",
      "global step 800, epoch: 1, batch: 800, loss: 0.58964, accu: 0.73938, speed: 9.69 step/s\r\n",
      "800 eval loss: 0.56902, accuracy: 0.74257\r\n",
      "global step 810, epoch: 1, batch: 810, loss: 0.63437, accu: 0.72500, speed: 1.16 step/s\r\n",
      "global step 820, epoch: 1, batch: 820, loss: 0.46441, accu: 0.73750, speed: 9.69 step/s\r\n",
      "global step 830, epoch: 1, batch: 830, loss: 0.70380, accu: 0.74062, speed: 9.65 step/s\r\n",
      "global step 840, epoch: 1, batch: 840, loss: 0.43262, accu: 0.74297, speed: 9.69 step/s\r\n",
      "global step 850, epoch: 1, batch: 850, loss: 0.73923, accu: 0.74250, speed: 9.74 step/s\r\n",
      "global step 860, epoch: 1, batch: 860, loss: 0.62496, accu: 0.74375, speed: 9.69 step/s\r\n",
      "global step 870, epoch: 1, batch: 870, loss: 0.48059, accu: 0.74062, speed: 9.71 step/s\r\n",
      "global step 880, epoch: 1, batch: 880, loss: 0.45044, accu: 0.74648, speed: 9.65 step/s\r\n",
      "global step 890, epoch: 1, batch: 890, loss: 0.76493, accu: 0.74687, speed: 9.72 step/s\r\n",
      "global step 900, epoch: 2, batch: 8, loss: 0.56556, accu: 0.74937, speed: 8.51 step/s\r\n",
      "900 eval loss: 0.57485, accuracy: 0.75575\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-27 22:14:56,469] [    INFO] - tokenizer config file saved in new_ernie_ckpt/tokenizer_config.json\r\n",
      "[2024-03-27 22:14:56,473] [    INFO] - Special tokens file saved in new_ernie_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 910, epoch: 2, batch: 18, loss: 0.43813, accu: 0.76562, speed: 0.89 step/s\r\n",
      "global step 920, epoch: 2, batch: 28, loss: 0.46779, accu: 0.77031, speed: 9.75 step/s\r\n",
      "global step 930, epoch: 2, batch: 38, loss: 0.41453, accu: 0.77083, speed: 9.26 step/s\r\n",
      "global step 940, epoch: 2, batch: 48, loss: 0.46373, accu: 0.77656, speed: 8.70 step/s\r\n",
      "global step 950, epoch: 2, batch: 58, loss: 0.59300, accu: 0.78125, speed: 7.97 step/s\r\n",
      "global step 960, epoch: 2, batch: 68, loss: 0.63839, accu: 0.77500, speed: 9.69 step/s\r\n",
      "global step 970, epoch: 2, batch: 78, loss: 0.57960, accu: 0.77589, speed: 9.68 step/s\r\n",
      "global step 980, epoch: 2, batch: 88, loss: 0.49007, accu: 0.77773, speed: 9.69 step/s\r\n",
      "global step 990, epoch: 2, batch: 98, loss: 0.45005, accu: 0.77743, speed: 9.68 step/s\r\n",
      "global step 1000, epoch: 2, batch: 108, loss: 0.80670, accu: 0.77719, speed: 9.54 step/s\r\n",
      "1000 eval loss: 0.56588, accuracy: 0.74930\r\n",
      "global step 1010, epoch: 2, batch: 118, loss: 0.50203, accu: 0.77500, speed: 1.16 step/s\r\n",
      "global step 1020, epoch: 2, batch: 128, loss: 0.42876, accu: 0.79688, speed: 8.78 step/s\r\n",
      "global step 1030, epoch: 2, batch: 138, loss: 0.44320, accu: 0.78333, speed: 8.77 step/s\r\n",
      "global step 1040, epoch: 2, batch: 148, loss: 0.53869, accu: 0.77266, speed: 8.69 step/s\r\n",
      "global step 1050, epoch: 2, batch: 158, loss: 0.41617, accu: 0.76562, speed: 8.86 step/s\r\n",
      "global step 1060, epoch: 2, batch: 168, loss: 0.57362, accu: 0.76771, speed: 8.89 step/s\r\n",
      "global step 1070, epoch: 2, batch: 178, loss: 0.43524, accu: 0.77054, speed: 8.59 step/s\r\n",
      "global step 1080, epoch: 2, batch: 188, loss: 0.56283, accu: 0.76875, speed: 8.95 step/s\r\n",
      "global step 1090, epoch: 2, batch: 198, loss: 0.66610, accu: 0.77187, speed: 8.76 step/s\r\n",
      "global step 1100, epoch: 2, batch: 208, loss: 0.44548, accu: 0.77500, speed: 9.68 step/s\r\n",
      "1100 eval loss: 0.56888, accuracy: 0.75547\r\n",
      "global step 1110, epoch: 2, batch: 218, loss: 0.36394, accu: 0.79063, speed: 1.17 step/s\r\n",
      "global step 1120, epoch: 2, batch: 228, loss: 0.45700, accu: 0.79219, speed: 9.66 step/s\r\n",
      "global step 1130, epoch: 2, batch: 238, loss: 0.54462, accu: 0.79375, speed: 9.50 step/s\r\n",
      "global step 1140, epoch: 2, batch: 248, loss: 0.53780, accu: 0.78047, speed: 9.60 step/s\r\n",
      "global step 1150, epoch: 2, batch: 258, loss: 0.61217, accu: 0.77750, speed: 9.25 step/s\r\n",
      "global step 1160, epoch: 2, batch: 268, loss: 0.58874, accu: 0.77344, speed: 9.58 step/s\r\n",
      "global step 1170, epoch: 2, batch: 278, loss: 0.40880, accu: 0.77232, speed: 9.63 step/s\r\n",
      "global step 1180, epoch: 2, batch: 288, loss: 0.47100, accu: 0.76797, speed: 9.59 step/s\r\n",
      "global step 1190, epoch: 2, batch: 298, loss: 0.32660, accu: 0.76944, speed: 9.55 step/s\r\n",
      "global step 1200, epoch: 2, batch: 308, loss: 0.68658, accu: 0.76844, speed: 9.52 step/s\r\n",
      "1200 eval loss: 0.57873, accuracy: 0.75042\r\n",
      "global step 1210, epoch: 2, batch: 318, loss: 0.57343, accu: 0.77500, speed: 1.15 step/s\r\n",
      "global step 1220, epoch: 2, batch: 328, loss: 0.41987, accu: 0.78906, speed: 9.61 step/s\r\n",
      "global step 1230, epoch: 2, batch: 338, loss: 0.77688, accu: 0.78333, speed: 9.53 step/s\r\n",
      "global step 1240, epoch: 2, batch: 348, loss: 0.38956, accu: 0.77422, speed: 9.52 step/s\r\n",
      "global step 1250, epoch: 2, batch: 358, loss: 0.54161, accu: 0.77250, speed: 9.33 step/s\r\n",
      "global step 1260, epoch: 2, batch: 368, loss: 0.59901, accu: 0.76771, speed: 9.57 step/s\r\n",
      "global step 1270, epoch: 2, batch: 378, loss: 0.36804, accu: 0.76652, speed: 9.41 step/s\r\n",
      "global step 1280, epoch: 2, batch: 388, loss: 0.44084, accu: 0.76719, speed: 9.55 step/s\r\n",
      "global step 1290, epoch: 2, batch: 398, loss: 0.61169, accu: 0.77153, speed: 9.46 step/s\r\n",
      "global step 1300, epoch: 2, batch: 408, loss: 0.36260, accu: 0.77344, speed: 9.14 step/s\r\n",
      "1300 eval loss: 0.57867, accuracy: 0.74706\r\n",
      "global step 1310, epoch: 2, batch: 418, loss: 0.51024, accu: 0.77500, speed: 1.15 step/s\r\n",
      "global step 1320, epoch: 2, batch: 428, loss: 0.52322, accu: 0.78281, speed: 9.58 step/s\r\n",
      "global step 1330, epoch: 2, batch: 438, loss: 0.47729, accu: 0.76979, speed: 9.58 step/s\r\n",
      "global step 1340, epoch: 2, batch: 448, loss: 0.43637, accu: 0.77969, speed: 9.50 step/s\r\n",
      "global step 1350, epoch: 2, batch: 458, loss: 0.46909, accu: 0.78375, speed: 9.60 step/s\r\n",
      "global step 1360, epoch: 2, batch: 468, loss: 0.55609, accu: 0.78333, speed: 9.54 step/s\r\n",
      "global step 1370, epoch: 2, batch: 478, loss: 0.50041, accu: 0.78170, speed: 9.65 step/s\r\n",
      "global step 1380, epoch: 2, batch: 488, loss: 0.56917, accu: 0.77734, speed: 9.52 step/s\r\n",
      "global step 1390, epoch: 2, batch: 498, loss: 0.57140, accu: 0.77674, speed: 9.60 step/s\r\n",
      "global step 1400, epoch: 2, batch: 508, loss: 0.47955, accu: 0.78187, speed: 9.60 step/s\r\n",
      "1400 eval loss: 0.58011, accuracy: 0.75435\r\n",
      "global step 1410, epoch: 2, batch: 518, loss: 0.62145, accu: 0.75313, speed: 1.18 step/s\r\n",
      "global step 1420, epoch: 2, batch: 528, loss: 0.66862, accu: 0.75625, speed: 9.56 step/s\r\n",
      "global step 1430, epoch: 2, batch: 538, loss: 0.40359, accu: 0.76667, speed: 9.68 step/s\r\n",
      "global step 1440, epoch: 2, batch: 548, loss: 0.41179, accu: 0.77031, speed: 9.17 step/s\r\n",
      "global step 1450, epoch: 2, batch: 558, loss: 0.45234, accu: 0.77563, speed: 9.64 step/s\r\n",
      "global step 1460, epoch: 2, batch: 568, loss: 0.75612, accu: 0.76875, speed: 9.62 step/s\r\n",
      "global step 1470, epoch: 2, batch: 578, loss: 0.47672, accu: 0.76161, speed: 9.55 step/s\r\n",
      "global step 1480, epoch: 2, batch: 588, loss: 0.39830, accu: 0.76602, speed: 9.63 step/s\r\n",
      "global step 1490, epoch: 2, batch: 598, loss: 0.52107, accu: 0.76493, speed: 9.62 step/s\r\n",
      "global step 1500, epoch: 2, batch: 608, loss: 0.70541, accu: 0.76281, speed: 9.61 step/s\r\n",
      "1500 eval loss: 0.57414, accuracy: 0.75238\r\n",
      "global step 1510, epoch: 2, batch: 618, loss: 0.60937, accu: 0.78125, speed: 1.17 step/s\r\n",
      "global step 1520, epoch: 2, batch: 628, loss: 0.43010, accu: 0.77500, speed: 9.62 step/s\r\n",
      "global step 1530, epoch: 2, batch: 638, loss: 0.64247, accu: 0.76458, speed: 9.44 step/s\r\n",
      "global step 1540, epoch: 2, batch: 648, loss: 0.67370, accu: 0.76406, speed: 9.59 step/s\r\n",
      "global step 1550, epoch: 2, batch: 658, loss: 0.46314, accu: 0.76438, speed: 9.67 step/s\r\n",
      "global step 1560, epoch: 2, batch: 668, loss: 0.53389, accu: 0.75677, speed: 9.12 step/s\r\n",
      "global step 1570, epoch: 2, batch: 678, loss: 0.45266, accu: 0.75804, speed: 8.83 step/s\r\n",
      "global step 1580, epoch: 2, batch: 688, loss: 0.69319, accu: 0.75938, speed: 7.38 step/s\r\n",
      "global step 1590, epoch: 2, batch: 698, loss: 0.44953, accu: 0.76042, speed: 8.35 step/s\r\n",
      "global step 1600, epoch: 2, batch: 708, loss: 0.48323, accu: 0.75813, speed: 9.61 step/s\r\n",
      "1600 eval loss: 0.59274, accuracy: 0.74678\r\n",
      "global step 1610, epoch: 2, batch: 718, loss: 0.43259, accu: 0.73438, speed: 1.16 step/s\r\n",
      "global step 1620, epoch: 2, batch: 728, loss: 0.42908, accu: 0.73594, speed: 9.63 step/s\r\n",
      "global step 1630, epoch: 2, batch: 738, loss: 0.62671, accu: 0.74792, speed: 9.69 step/s\r\n",
      "global step 1640, epoch: 2, batch: 748, loss: 0.67654, accu: 0.75234, speed: 9.60 step/s\r\n",
      "global step 1650, epoch: 2, batch: 758, loss: 0.43667, accu: 0.76250, speed: 9.60 step/s\r\n",
      "global step 1660, epoch: 2, batch: 768, loss: 0.43558, accu: 0.76146, speed: 9.57 step/s\r\n",
      "global step 1670, epoch: 2, batch: 778, loss: 0.42037, accu: 0.76607, speed: 9.60 step/s\r\n",
      "global step 1680, epoch: 2, batch: 788, loss: 0.30891, accu: 0.76562, speed: 9.56 step/s\r\n",
      "global step 1690, epoch: 2, batch: 798, loss: 0.35714, accu: 0.76667, speed: 9.59 step/s\r\n",
      "global step 1700, epoch: 2, batch: 808, loss: 0.42274, accu: 0.76344, speed: 9.51 step/s\r\n",
      "1700 eval loss: 0.57323, accuracy: 0.75294\r\n",
      "global step 1710, epoch: 2, batch: 818, loss: 0.42283, accu: 0.76875, speed: 1.14 step/s\r\n",
      "global step 1720, epoch: 2, batch: 828, loss: 0.46595, accu: 0.78906, speed: 9.58 step/s\r\n",
      "global step 1730, epoch: 2, batch: 838, loss: 0.42703, accu: 0.78542, speed: 9.52 step/s\r\n",
      "global step 1740, epoch: 2, batch: 848, loss: 0.80172, accu: 0.77578, speed: 9.56 step/s\r\n",
      "global step 1750, epoch: 2, batch: 858, loss: 0.53324, accu: 0.76687, speed: 9.50 step/s\r\n",
      "global step 1760, epoch: 2, batch: 868, loss: 0.38978, accu: 0.77656, speed: 9.59 step/s\r\n",
      "global step 1770, epoch: 2, batch: 878, loss: 0.43698, accu: 0.77545, speed: 9.23 step/s\r\n",
      "global step 1780, epoch: 2, batch: 888, loss: 0.48535, accu: 0.76953, speed: 9.60 step/s\r\n",
      "global step 1790, epoch: 3, batch: 6, loss: 0.39971, accu: 0.77301, speed: 8.52 step/s\r\n",
      "global step 1800, epoch: 3, batch: 16, loss: 0.29494, accu: 0.77666, speed: 9.57 step/s\r\n",
      "1800 eval loss: 0.57117, accuracy: 0.75603\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-27 22:17:44,082] [    INFO] - tokenizer config file saved in new_ernie_ckpt/tokenizer_config.json\r\n",
      "[2024-03-27 22:17:44,098] [    INFO] - Special tokens file saved in new_ernie_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 1810, epoch: 3, batch: 26, loss: 0.59608, accu: 0.82500, speed: 0.84 step/s\r\n",
      "global step 1820, epoch: 3, batch: 36, loss: 0.53110, accu: 0.80469, speed: 9.58 step/s\r\n",
      "global step 1830, epoch: 3, batch: 46, loss: 0.31444, accu: 0.80208, speed: 9.59 step/s\r\n",
      "global step 1840, epoch: 3, batch: 56, loss: 0.36550, accu: 0.79297, speed: 9.60 step/s\r\n",
      "global step 1850, epoch: 3, batch: 66, loss: 0.39227, accu: 0.79812, speed: 9.60 step/s\r\n",
      "global step 1860, epoch: 3, batch: 76, loss: 0.52328, accu: 0.80208, speed: 9.10 step/s\r\n",
      "global step 1870, epoch: 3, batch: 86, loss: 0.35861, accu: 0.80268, speed: 9.56 step/s\r\n",
      "global step 1880, epoch: 3, batch: 96, loss: 0.35141, accu: 0.80547, speed: 9.57 step/s\r\n",
      "global step 1890, epoch: 3, batch: 106, loss: 0.42680, accu: 0.80694, speed: 9.57 step/s\r\n",
      "global step 1900, epoch: 3, batch: 116, loss: 0.91381, accu: 0.80500, speed: 9.57 step/s\r\n",
      "1900 eval loss: 0.60727, accuracy: 0.74004\r\n",
      "global step 1910, epoch: 3, batch: 126, loss: 0.31703, accu: 0.82500, speed: 1.12 step/s\r\n",
      "global step 1920, epoch: 3, batch: 136, loss: 0.34235, accu: 0.81406, speed: 9.48 step/s\r\n",
      "global step 1930, epoch: 3, batch: 146, loss: 0.41016, accu: 0.81771, speed: 8.34 step/s\r\n",
      "global step 1940, epoch: 3, batch: 156, loss: 0.67339, accu: 0.81016, speed: 9.35 step/s\r\n",
      "global step 1950, epoch: 3, batch: 166, loss: 0.46509, accu: 0.80375, speed: 9.56 step/s\r\n",
      "global step 1960, epoch: 3, batch: 176, loss: 0.40186, accu: 0.79635, speed: 9.58 step/s\r\n",
      "global step 1970, epoch: 3, batch: 186, loss: 0.53575, accu: 0.80179, speed: 9.34 step/s\r\n",
      "global step 1980, epoch: 3, batch: 196, loss: 0.73464, accu: 0.80039, speed: 9.57 step/s\r\n",
      "global step 1990, epoch: 3, batch: 206, loss: 0.31097, accu: 0.80000, speed: 9.55 step/s\r\n",
      "global step 2000, epoch: 3, batch: 216, loss: 0.42885, accu: 0.79844, speed: 9.57 step/s\r\n",
      "2000 eval loss: 0.62071, accuracy: 0.73163\r\n",
      "global step 2010, epoch: 3, batch: 226, loss: 0.41135, accu: 0.80937, speed: 1.17 step/s\r\n",
      "global step 2020, epoch: 3, batch: 236, loss: 0.70562, accu: 0.80625, speed: 9.56 step/s\r\n",
      "global step 2030, epoch: 3, batch: 246, loss: 0.55656, accu: 0.80417, speed: 9.61 step/s\r\n",
      "global step 2040, epoch: 3, batch: 256, loss: 0.25841, accu: 0.80703, speed: 9.22 step/s\r\n",
      "global step 2050, epoch: 3, batch: 266, loss: 0.38449, accu: 0.80875, speed: 9.53 step/s\r\n",
      "global step 2060, epoch: 3, batch: 276, loss: 0.36063, accu: 0.80833, speed: 9.41 step/s\r\n",
      "global step 2070, epoch: 3, batch: 286, loss: 0.42053, accu: 0.80580, speed: 9.54 step/s\r\n",
      "global step 2080, epoch: 3, batch: 296, loss: 0.66056, accu: 0.80586, speed: 9.59 step/s\r\n",
      "global step 2090, epoch: 3, batch: 306, loss: 0.25191, accu: 0.80729, speed: 9.52 step/s\r\n",
      "global step 2100, epoch: 3, batch: 316, loss: 0.55587, accu: 0.80812, speed: 9.54 step/s\r\n",
      "2100 eval loss: 0.59743, accuracy: 0.74201\r\n",
      "global step 2110, epoch: 3, batch: 326, loss: 0.41395, accu: 0.79688, speed: 1.20 step/s\r\n",
      "global step 2120, epoch: 3, batch: 336, loss: 0.68589, accu: 0.78438, speed: 9.50 step/s\r\n",
      "global step 2130, epoch: 3, batch: 346, loss: 0.44837, accu: 0.78750, speed: 9.58 step/s\r\n",
      "global step 2140, epoch: 3, batch: 356, loss: 0.53814, accu: 0.78594, speed: 9.53 step/s\r\n",
      "global step 2150, epoch: 3, batch: 366, loss: 0.53140, accu: 0.79063, speed: 9.53 step/s\r\n",
      "global step 2160, epoch: 3, batch: 376, loss: 0.36257, accu: 0.79167, speed: 9.54 step/s\r\n",
      "global step 2170, epoch: 3, batch: 386, loss: 0.52703, accu: 0.79241, speed: 9.47 step/s\r\n",
      "global step 2180, epoch: 3, batch: 396, loss: 0.25636, accu: 0.79609, speed: 9.54 step/s\r\n",
      "global step 2190, epoch: 3, batch: 406, loss: 0.32413, accu: 0.79340, speed: 9.56 step/s\r\n",
      "global step 2200, epoch: 3, batch: 416, loss: 0.38300, accu: 0.79531, speed: 9.52 step/s\r\n",
      "2200 eval loss: 0.58829, accuracy: 0.74790\r\n",
      "global step 2210, epoch: 3, batch: 426, loss: 0.45641, accu: 0.79375, speed: 1.18 step/s\r\n",
      "global step 2220, epoch: 3, batch: 436, loss: 0.51785, accu: 0.81875, speed: 9.56 step/s\r\n",
      "global step 2230, epoch: 3, batch: 446, loss: 0.63366, accu: 0.81563, speed: 9.56 step/s\r\n",
      "global step 2240, epoch: 3, batch: 456, loss: 0.46151, accu: 0.80547, speed: 9.56 step/s\r\n",
      "global step 2250, epoch: 3, batch: 466, loss: 0.31067, accu: 0.80563, speed: 9.51 step/s\r\n",
      "global step 2260, epoch: 3, batch: 476, loss: 0.42509, accu: 0.80260, speed: 9.54 step/s\r\n",
      "global step 2270, epoch: 3, batch: 486, loss: 0.64056, accu: 0.80402, speed: 9.58 step/s\r\n",
      "global step 2280, epoch: 3, batch: 496, loss: 0.36599, accu: 0.80039, speed: 9.49 step/s\r\n",
      "global step 2290, epoch: 3, batch: 506, loss: 0.37033, accu: 0.80278, speed: 9.47 step/s\r\n",
      "global step 2300, epoch: 3, batch: 516, loss: 0.56940, accu: 0.80375, speed: 9.59 step/s\r\n",
      "2300 eval loss: 0.60113, accuracy: 0.74425\r\n",
      "global step 2310, epoch: 3, batch: 526, loss: 0.37732, accu: 0.79688, speed: 1.18 step/s\r\n",
      "global step 2320, epoch: 3, batch: 536, loss: 0.40849, accu: 0.78906, speed: 9.59 step/s\r\n",
      "global step 2330, epoch: 3, batch: 546, loss: 0.60387, accu: 0.79792, speed: 9.53 step/s\r\n",
      "global step 2340, epoch: 3, batch: 556, loss: 0.54748, accu: 0.78672, speed: 9.58 step/s\r\n",
      "global step 2350, epoch: 3, batch: 566, loss: 0.30282, accu: 0.78438, speed: 9.56 step/s\r\n",
      "global step 2360, epoch: 3, batch: 576, loss: 0.37663, accu: 0.79010, speed: 9.49 step/s\r\n",
      "global step 2370, epoch: 3, batch: 586, loss: 0.42226, accu: 0.78705, speed: 9.56 step/s\r\n",
      "global step 2380, epoch: 3, batch: 596, loss: 0.41052, accu: 0.78711, speed: 9.57 step/s\r\n",
      "global step 2390, epoch: 3, batch: 606, loss: 0.40009, accu: 0.78681, speed: 9.61 step/s\r\n",
      "global step 2400, epoch: 3, batch: 616, loss: 0.42051, accu: 0.79031, speed: 9.49 step/s\r\n",
      "2400 eval loss: 0.58056, accuracy: 0.75042\r\n",
      "global step 2410, epoch: 3, batch: 626, loss: 0.49275, accu: 0.82500, speed: 1.17 step/s\r\n",
      "global step 2420, epoch: 3, batch: 636, loss: 0.47824, accu: 0.82031, speed: 9.59 step/s\r\n",
      "global step 2430, epoch: 3, batch: 646, loss: 0.39247, accu: 0.81563, speed: 9.27 step/s\r\n",
      "global step 2440, epoch: 3, batch: 656, loss: 0.49494, accu: 0.80547, speed: 9.65 step/s\r\n",
      "global step 2450, epoch: 3, batch: 666, loss: 0.33810, accu: 0.80000, speed: 9.22 step/s\r\n",
      "global step 2460, epoch: 3, batch: 676, loss: 0.35881, accu: 0.80781, speed: 9.56 step/s\r\n",
      "global step 2470, epoch: 3, batch: 686, loss: 0.45297, accu: 0.80179, speed: 9.55 step/s\r\n",
      "global step 2480, epoch: 3, batch: 696, loss: 0.76567, accu: 0.80039, speed: 9.56 step/s\r\n",
      "global step 2490, epoch: 3, batch: 706, loss: 0.43282, accu: 0.80556, speed: 8.33 step/s\r\n",
      "global step 2500, epoch: 3, batch: 716, loss: 0.52749, accu: 0.80719, speed: 8.62 step/s\r\n",
      "2500 eval loss: 0.61540, accuracy: 0.74902\r\n",
      "global step 2510, epoch: 3, batch: 726, loss: 0.52388, accu: 0.77500, speed: 1.16 step/s\r\n",
      "global step 2520, epoch: 3, batch: 736, loss: 0.32893, accu: 0.80312, speed: 9.65 step/s\r\n",
      "global step 2530, epoch: 3, batch: 746, loss: 0.47863, accu: 0.80312, speed: 9.59 step/s\r\n",
      "global step 2540, epoch: 3, batch: 756, loss: 0.36788, accu: 0.80000, speed: 9.26 step/s\r\n",
      "global step 2550, epoch: 3, batch: 766, loss: 0.34656, accu: 0.80250, speed: 9.57 step/s\r\n",
      "global step 2560, epoch: 3, batch: 776, loss: 0.58691, accu: 0.80052, speed: 9.52 step/s\r\n",
      "global step 2570, epoch: 3, batch: 786, loss: 0.31904, accu: 0.80134, speed: 9.63 step/s\r\n",
      "global step 2580, epoch: 3, batch: 796, loss: 0.63605, accu: 0.79648, speed: 9.62 step/s\r\n",
      "global step 2590, epoch: 3, batch: 806, loss: 0.40981, accu: 0.79583, speed: 9.57 step/s\r\n",
      "global step 2600, epoch: 3, batch: 816, loss: 0.33410, accu: 0.79531, speed: 9.11 step/s\r\n",
      "2600 eval loss: 0.58526, accuracy: 0.75519\r\n",
      "global step 2610, epoch: 3, batch: 826, loss: 0.29580, accu: 0.80625, speed: 1.18 step/s\r\n",
      "global step 2620, epoch: 3, batch: 836, loss: 0.42475, accu: 0.80469, speed: 9.54 step/s\r\n",
      "global step 2630, epoch: 3, batch: 846, loss: 0.30356, accu: 0.81354, speed: 9.50 step/s\r\n",
      "global step 2640, epoch: 3, batch: 856, loss: 0.43407, accu: 0.80859, speed: 9.59 step/s\r\n",
      "global step 2650, epoch: 3, batch: 866, loss: 0.39718, accu: 0.79937, speed: 9.59 step/s\r\n",
      "global step 2660, epoch: 3, batch: 876, loss: 0.55497, accu: 0.79115, speed: 9.55 step/s\r\n",
      "global step 2670, epoch: 3, batch: 886, loss: 0.62259, accu: 0.78973, speed: 9.56 step/s\r\n",
      "global step 2680, epoch: 4, batch: 4, loss: 0.41244, accu: 0.79160, speed: 8.49 step/s\r\n",
      "global step 2690, epoch: 4, batch: 14, loss: 0.38969, accu: 0.79742, speed: 9.54 step/s\r\n",
      "global step 2700, epoch: 4, batch: 24, loss: 0.55120, accu: 0.80521, speed: 9.51 step/s\r\n",
      "2700 eval loss: 0.64031, accuracy: 0.75743\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-27 22:20:29,833] [    INFO] - tokenizer config file saved in new_ernie_ckpt/tokenizer_config.json\r\n",
      "[2024-03-27 22:20:29,836] [    INFO] - Special tokens file saved in new_ernie_ckpt/special_tokens_map.json\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global step 2710, epoch: 4, batch: 34, loss: 0.56641, accu: 0.82500, speed: 0.87 step/s\r\n",
      "global step 2720, epoch: 4, batch: 44, loss: 0.41351, accu: 0.83281, speed: 9.57 step/s\r\n",
      "global step 2730, epoch: 4, batch: 54, loss: 0.41019, accu: 0.83750, speed: 9.52 step/s\r\n",
      "global step 2740, epoch: 4, batch: 64, loss: 0.28182, accu: 0.85000, speed: 9.52 step/s\r\n",
      "global step 2750, epoch: 4, batch: 74, loss: 0.28908, accu: 0.84937, speed: 9.58 step/s\r\n",
      "global step 2760, epoch: 4, batch: 84, loss: 0.32912, accu: 0.85260, speed: 9.55 step/s\r\n",
      "global step 2770, epoch: 4, batch: 94, loss: 0.47178, accu: 0.84821, speed: 9.58 step/s\r\n",
      "global step 2780, epoch: 4, batch: 104, loss: 0.31442, accu: 0.85156, speed: 9.18 step/s\r\n",
      "global step 2790, epoch: 4, batch: 114, loss: 0.31457, accu: 0.85243, speed: 9.52 step/s\r\n",
      "global step 2800, epoch: 4, batch: 124, loss: 0.31972, accu: 0.84875, speed: 9.59 step/s\r\n",
      "2800 eval loss: 0.64816, accuracy: 0.75070\r\n",
      "global step 2810, epoch: 4, batch: 134, loss: 0.25362, accu: 0.85000, speed: 1.17 step/s\r\n",
      "global step 2820, epoch: 4, batch: 144, loss: 0.25890, accu: 0.85781, speed: 9.52 step/s\r\n",
      "global step 2830, epoch: 4, batch: 154, loss: 0.43044, accu: 0.85000, speed: 9.55 step/s\r\n",
      "global step 2840, epoch: 4, batch: 164, loss: 0.35390, accu: 0.84609, speed: 9.38 step/s\r\n",
      "global step 2850, epoch: 4, batch: 174, loss: 0.44639, accu: 0.85188, speed: 9.41 step/s\r\n",
      "global step 2860, epoch: 4, batch: 184, loss: 0.19084, accu: 0.84740, speed: 9.57 step/s\r\n",
      "global step 2870, epoch: 4, batch: 194, loss: 0.46895, accu: 0.84464, speed: 9.55 step/s\r\n",
      "global step 2880, epoch: 4, batch: 204, loss: 0.39170, accu: 0.83984, speed: 9.46 step/s\r\n",
      "global step 2890, epoch: 4, batch: 214, loss: 0.44004, accu: 0.84097, speed: 9.54 step/s\r\n",
      "global step 2900, epoch: 4, batch: 224, loss: 0.59918, accu: 0.83969, speed: 9.46 step/s\r\n",
      "2900 eval loss: 0.60722, accuracy: 0.74173\r\n",
      "global step 2910, epoch: 4, batch: 234, loss: 0.25927, accu: 0.86562, speed: 1.15 step/s\r\n",
      "global step 2920, epoch: 4, batch: 244, loss: 0.16860, accu: 0.84688, speed: 9.36 step/s\r\n",
      "global step 2930, epoch: 4, batch: 254, loss: 0.46677, accu: 0.82292, speed: 9.53 step/s\r\n",
      "global step 2940, epoch: 4, batch: 264, loss: 0.31908, accu: 0.82422, speed: 9.47 step/s\r\n",
      "global step 2950, epoch: 4, batch: 274, loss: 0.46254, accu: 0.82563, speed: 9.51 step/s\r\n",
      "global step 2960, epoch: 4, batch: 284, loss: 0.58858, accu: 0.83125, speed: 9.53 step/s\r\n",
      "global step 2970, epoch: 4, batch: 294, loss: 0.24249, accu: 0.83348, speed: 9.55 step/s\r\n",
      "global step 2980, epoch: 4, batch: 304, loss: 0.16857, accu: 0.83555, speed: 9.22 step/s\r\n",
      "global step 2990, epoch: 4, batch: 314, loss: 0.53500, accu: 0.83542, speed: 9.54 step/s\r\n",
      "global step 3000, epoch: 4, batch: 324, loss: 0.31157, accu: 0.83844, speed: 9.52 step/s\r\n",
      "3000 eval loss: 0.61620, accuracy: 0.74145\r\n",
      "global step 3010, epoch: 4, batch: 334, loss: 0.15731, accu: 0.87813, speed: 1.15 step/s\r\n",
      "global step 3020, epoch: 4, batch: 344, loss: 0.25449, accu: 0.86406, speed: 9.44 step/s\r\n",
      "global step 3030, epoch: 4, batch: 354, loss: 0.54505, accu: 0.84271, speed: 9.48 step/s\r\n",
      "global step 3040, epoch: 4, batch: 364, loss: 0.37388, accu: 0.84219, speed: 9.55 step/s\r\n",
      "global step 3050, epoch: 4, batch: 374, loss: 0.45765, accu: 0.84188, speed: 9.59 step/s\r\n",
      "global step 3060, epoch: 4, batch: 384, loss: 0.45556, accu: 0.83854, speed: 9.55 step/s\r\n",
      "global step 3070, epoch: 4, batch: 394, loss: 0.57706, accu: 0.83304, speed: 9.12 step/s\r\n",
      "global step 3080, epoch: 4, batch: 404, loss: 0.33341, accu: 0.83281, speed: 9.63 step/s\r\n",
      "global step 3090, epoch: 4, batch: 414, loss: 0.46415, accu: 0.83160, speed: 9.52 step/s\r\n",
      "global step 3100, epoch: 4, batch: 424, loss: 0.43439, accu: 0.83344, speed: 9.54 step/s\r\n",
      "3100 eval loss: 0.64174, accuracy: 0.73864\r\n",
      "global step 3110, epoch: 4, batch: 434, loss: 0.63255, accu: 0.80937, speed: 1.17 step/s\r\n",
      "global step 3120, epoch: 4, batch: 444, loss: 0.28392, accu: 0.83750, speed: 9.65 step/s\r\n",
      "global step 3130, epoch: 4, batch: 454, loss: 0.29671, accu: 0.84271, speed: 9.03 step/s\r\n",
      "global step 3140, epoch: 4, batch: 464, loss: 0.67251, accu: 0.83750, speed: 9.64 step/s\r\n",
      "global step 3150, epoch: 4, batch: 474, loss: 0.59588, accu: 0.83437, speed: 9.62 step/s\r\n",
      "global step 3160, epoch: 4, batch: 484, loss: 0.46542, accu: 0.83021, speed: 9.62 step/s\r\n",
      "global step 3170, epoch: 4, batch: 494, loss: 0.39799, accu: 0.82679, speed: 9.62 step/s\r\n",
      "global step 3180, epoch: 4, batch: 504, loss: 0.36841, accu: 0.82969, speed: 9.67 step/s\r\n",
      "global step 3190, epoch: 4, batch: 514, loss: 0.38701, accu: 0.83299, speed: 9.49 step/s\r\n",
      "global step 3200, epoch: 4, batch: 524, loss: 0.58134, accu: 0.83125, speed: 9.50 step/s\r\n",
      "3200 eval loss: 0.62329, accuracy: 0.74649\r\n",
      "global step 3210, epoch: 4, batch: 534, loss: 0.26065, accu: 0.87813, speed: 1.18 step/s\r\n",
      "global step 3220, epoch: 4, batch: 544, loss: 0.43595, accu: 0.85781, speed: 9.62 step/s\r\n",
      "global step 3230, epoch: 4, batch: 554, loss: 0.39108, accu: 0.85625, speed: 9.65 step/s\r\n",
      "global step 3240, epoch: 4, batch: 564, loss: 0.32477, accu: 0.84141, speed: 9.65 step/s\r\n",
      "global step 3250, epoch: 4, batch: 574, loss: 0.43207, accu: 0.84625, speed: 9.62 step/s\r\n",
      "global step 3260, epoch: 4, batch: 584, loss: 0.45897, accu: 0.84427, speed: 9.56 step/s\r\n",
      "global step 3270, epoch: 4, batch: 594, loss: 0.21717, accu: 0.84375, speed: 9.24 step/s\r\n",
      "global step 3280, epoch: 4, batch: 604, loss: 0.38768, accu: 0.84297, speed: 9.68 step/s\r\n",
      "global step 3290, epoch: 4, batch: 614, loss: 0.43114, accu: 0.84062, speed: 9.69 step/s\r\n",
      "global step 3300, epoch: 4, batch: 624, loss: 0.34565, accu: 0.83813, speed: 9.59 step/s\r\n",
      "3300 eval loss: 0.60549, accuracy: 0.74565\r\n",
      "global step 3310, epoch: 4, batch: 634, loss: 0.42897, accu: 0.88750, speed: 1.18 step/s\r\n",
      "global step 3320, epoch: 4, batch: 644, loss: 0.26540, accu: 0.86875, speed: 8.92 step/s\r\n",
      "global step 3330, epoch: 4, batch: 654, loss: 0.23543, accu: 0.85938, speed: 9.65 step/s\r\n",
      "global step 3340, epoch: 4, batch: 664, loss: 0.64950, accu: 0.84141, speed: 9.63 step/s\r\n",
      "global step 3350, epoch: 4, batch: 674, loss: 0.45481, accu: 0.83562, speed: 9.65 step/s\r\n",
      "global step 3360, epoch: 4, batch: 684, loss: 0.48824, accu: 0.82812, speed: 9.63 step/s\r\n",
      "global step 3370, epoch: 4, batch: 694, loss: 0.28342, accu: 0.83080, speed: 9.50 step/s\r\n",
      "global step 3380, epoch: 4, batch: 704, loss: 0.51467, accu: 0.83281, speed: 9.63 step/s\r\n",
      "global step 3390, epoch: 4, batch: 714, loss: 0.34347, accu: 0.83507, speed: 9.56 step/s\r\n",
      "global step 3400, epoch: 4, batch: 724, loss: 0.33767, accu: 0.83719, speed: 9.63 step/s\r\n",
      "3400 eval loss: 0.68019, accuracy: 0.74033\r\n",
      "global step 3410, epoch: 4, batch: 734, loss: 0.33304, accu: 0.85000, speed: 1.18 step/s\r\n",
      "global step 3420, epoch: 4, batch: 744, loss: 0.53447, accu: 0.85000, speed: 9.62 step/s\r\n",
      "global step 3430, epoch: 4, batch: 754, loss: 0.18882, accu: 0.86250, speed: 9.61 step/s\r\n",
      "global step 3440, epoch: 4, batch: 764, loss: 0.47009, accu: 0.85938, speed: 9.59 step/s\r\n",
      "global step 3450, epoch: 4, batch: 774, loss: 0.47170, accu: 0.85625, speed: 9.61 step/s\r\n",
      "global step 3460, epoch: 4, batch: 784, loss: 0.30237, accu: 0.84896, speed: 9.65 step/s\r\n",
      "global step 3470, epoch: 4, batch: 794, loss: 0.41398, accu: 0.84732, speed: 9.52 step/s\r\n",
      "global step 3480, epoch: 4, batch: 804, loss: 0.54544, accu: 0.84648, speed: 9.65 step/s\r\n",
      "global step 3490, epoch: 4, batch: 814, loss: 0.46850, accu: 0.84375, speed: 9.66 step/s\r\n",
      "global step 3500, epoch: 4, batch: 824, loss: 0.68708, accu: 0.84437, speed: 9.57 step/s\r\n",
      "3500 eval loss: 0.69876, accuracy: 0.73163\r\n",
      "global step 3510, epoch: 4, batch: 834, loss: 0.29031, accu: 0.83125, speed: 1.20 step/s\r\n",
      "global step 3520, epoch: 4, batch: 844, loss: 0.29548, accu: 0.82656, speed: 9.64 step/s\r\n",
      "global step 3530, epoch: 4, batch: 854, loss: 0.50065, accu: 0.82292, speed: 9.70 step/s\r\n",
      "global step 3540, epoch: 4, batch: 864, loss: 0.37451, accu: 0.81875, speed: 9.57 step/s\r\n",
      "global step 3550, epoch: 4, batch: 874, loss: 0.21098, accu: 0.81937, speed: 9.54 step/s\r\n",
      "global step 3560, epoch: 4, batch: 884, loss: 0.47972, accu: 0.81875, speed: 9.62 step/s\r\n",
      "global step 3570, epoch: 5, batch: 2, loss: 0.35176, accu: 0.81867, speed: 8.40 step/s\r\n",
      "global step 3580, epoch: 5, batch: 12, loss: 0.29085, accu: 0.82732, speed: 9.60 step/s\r\n",
      "global step 3590, epoch: 5, batch: 22, loss: 0.22760, accu: 0.83403, speed: 9.30 step/s\r\n",
      "global step 3600, epoch: 5, batch: 32, loss: 0.40910, accu: 0.84034, speed: 9.58 step/s\r\n",
      "3600 eval loss: 0.78982, accuracy: 0.73864\r\n",
      "global step 3610, epoch: 5, batch: 42, loss: 0.24870, accu: 0.90000, speed: 1.16 step/s\r\n",
      "global step 3620, epoch: 5, batch: 52, loss: 0.37774, accu: 0.89687, speed: 9.62 step/s\r\n",
      "global step 3630, epoch: 5, batch: 62, loss: 0.15618, accu: 0.88229, speed: 9.26 step/s\r\n",
      "global step 3640, epoch: 5, batch: 72, loss: 0.14491, accu: 0.88438, speed: 8.98 step/s\r\n",
      "global step 3650, epoch: 5, batch: 82, loss: 0.19658, accu: 0.89312, speed: 9.55 step/s\r\n",
      "global step 3660, epoch: 5, batch: 92, loss: 0.53986, accu: 0.88802, speed: 9.64 step/s\r\n",
      "global step 3670, epoch: 5, batch: 102, loss: 0.20721, accu: 0.88482, speed: 9.55 step/s\r\n",
      "global step 3680, epoch: 5, batch: 112, loss: 0.31937, accu: 0.87969, speed: 9.68 step/s\r\n",
      "global step 3690, epoch: 5, batch: 122, loss: 0.16249, accu: 0.87986, speed: 9.57 step/s\r\n",
      "global step 3700, epoch: 5, batch: 132, loss: 0.16387, accu: 0.87656, speed: 9.61 step/s\r\n",
      "3700 eval loss: 0.74073, accuracy: 0.73303\r\n",
      "global step 3710, epoch: 5, batch: 142, loss: 0.31417, accu: 0.87500, speed: 1.17 step/s\r\n",
      "global step 3720, epoch: 5, batch: 152, loss: 0.24462, accu: 0.88281, speed: 9.63 step/s\r\n",
      "global step 3730, epoch: 5, batch: 162, loss: 0.19997, accu: 0.88750, speed: 9.61 step/s\r\n",
      "global step 3740, epoch: 5, batch: 172, loss: 0.27062, accu: 0.89062, speed: 9.56 step/s\r\n",
      "global step 3750, epoch: 5, batch: 182, loss: 0.33006, accu: 0.88875, speed: 9.59 step/s\r\n",
      "global step 3760, epoch: 5, batch: 192, loss: 0.29682, accu: 0.89115, speed: 9.62 step/s\r\n",
      "global step 3770, epoch: 5, batch: 202, loss: 0.28740, accu: 0.89018, speed: 9.61 step/s\r\n",
      "global step 3780, epoch: 5, batch: 212, loss: 0.29868, accu: 0.88594, speed: 9.60 step/s\r\n",
      "global step 3790, epoch: 5, batch: 222, loss: 0.17010, accu: 0.88299, speed: 9.53 step/s\r\n",
      "global step 3800, epoch: 5, batch: 232, loss: 0.21273, accu: 0.88187, speed: 9.49 step/s\r\n",
      "3800 eval loss: 0.75535, accuracy: 0.73331\r\n",
      "global step 3810, epoch: 5, batch: 242, loss: 0.20109, accu: 0.87813, speed: 1.18 step/s\r\n",
      "global step 3820, epoch: 5, batch: 252, loss: 0.27025, accu: 0.87500, speed: 9.61 step/s\r\n",
      "global step 3830, epoch: 5, batch: 262, loss: 0.39964, accu: 0.87187, speed: 9.60 step/s\r\n",
      "global step 3840, epoch: 5, batch: 272, loss: 0.37840, accu: 0.87578, speed: 9.57 step/s\r\n",
      "global step 3850, epoch: 5, batch: 282, loss: 0.44186, accu: 0.87125, speed: 9.59 step/s\r\n",
      "global step 3860, epoch: 5, batch: 292, loss: 0.51382, accu: 0.86875, speed: 9.62 step/s\r\n",
      "global step 3870, epoch: 5, batch: 302, loss: 0.16974, accu: 0.86920, speed: 9.49 step/s\r\n",
      "global step 3880, epoch: 5, batch: 312, loss: 0.41981, accu: 0.87109, speed: 9.51 step/s\r\n",
      "global step 3890, epoch: 5, batch: 322, loss: 0.14536, accu: 0.87222, speed: 9.54 step/s\r\n",
      "global step 3900, epoch: 5, batch: 332, loss: 0.48625, accu: 0.87031, speed: 9.52 step/s\r\n",
      "3900 eval loss: 0.69870, accuracy: 0.73528\r\n",
      "global step 3910, epoch: 5, batch: 342, loss: 0.25082, accu: 0.90000, speed: 1.17 step/s\r\n",
      "global step 3920, epoch: 5, batch: 352, loss: 0.48531, accu: 0.90469, speed: 9.56 step/s\r\n",
      "global step 3930, epoch: 5, batch: 362, loss: 0.44020, accu: 0.89687, speed: 9.64 step/s\r\n",
      "global step 3940, epoch: 5, batch: 372, loss: 0.50031, accu: 0.89609, speed: 9.62 step/s\r\n",
      "global step 3950, epoch: 5, batch: 382, loss: 0.34345, accu: 0.90000, speed: 9.61 step/s\r\n",
      "global step 3960, epoch: 5, batch: 392, loss: 0.42860, accu: 0.89896, speed: 9.56 step/s\r\n",
      "global step 3970, epoch: 5, batch: 402, loss: 0.26431, accu: 0.89687, speed: 9.53 step/s\r\n",
      "global step 3980, epoch: 5, batch: 412, loss: 0.28261, accu: 0.89453, speed: 9.59 step/s\r\n",
      "global step 3990, epoch: 5, batch: 422, loss: 0.24993, accu: 0.89306, speed: 9.60 step/s\r\n",
      "global step 4000, epoch: 5, batch: 432, loss: 0.23591, accu: 0.89187, speed: 9.57 step/s\r\n",
      "4000 eval loss: 0.70958, accuracy: 0.74004\r\n",
      "global step 4010, epoch: 5, batch: 442, loss: 0.28962, accu: 0.86875, speed: 1.11 step/s\r\n",
      "global step 4020, epoch: 5, batch: 452, loss: 0.21968, accu: 0.85469, speed: 9.09 step/s\r\n",
      "global step 4030, epoch: 5, batch: 462, loss: 0.38692, accu: 0.85417, speed: 9.57 step/s\r\n",
      "global step 4040, epoch: 5, batch: 472, loss: 0.53493, accu: 0.86172, speed: 9.60 step/s\r\n",
      "global step 4050, epoch: 5, batch: 482, loss: 0.29945, accu: 0.86438, speed: 9.54 step/s\r\n",
      "global step 4060, epoch: 5, batch: 492, loss: 0.51911, accu: 0.86615, speed: 7.61 step/s\r\n",
      "global step 4070, epoch: 5, batch: 502, loss: 0.27226, accu: 0.86696, speed: 9.50 step/s\r\n",
      "global step 4080, epoch: 5, batch: 512, loss: 0.22934, accu: 0.87031, speed: 9.61 step/s\r\n",
      "global step 4090, epoch: 5, batch: 522, loss: 0.26785, accu: 0.86840, speed: 9.49 step/s\r\n",
      "global step 4100, epoch: 5, batch: 532, loss: 0.12125, accu: 0.87125, speed: 9.49 step/s\r\n",
      "4100 eval loss: 0.73007, accuracy: 0.73696\r\n",
      "global step 4110, epoch: 5, batch: 542, loss: 0.31205, accu: 0.87500, speed: 1.16 step/s\r\n",
      "global step 4120, epoch: 5, batch: 552, loss: 0.21434, accu: 0.86875, speed: 9.45 step/s\r\n",
      "global step 4130, epoch: 5, batch: 562, loss: 0.28593, accu: 0.86875, speed: 9.62 step/s\r\n",
      "global step 4140, epoch: 5, batch: 572, loss: 0.37058, accu: 0.87031, speed: 9.59 step/s\r\n",
      "global step 4150, epoch: 5, batch: 582, loss: 0.25028, accu: 0.87438, speed: 9.56 step/s\r\n",
      "global step 4160, epoch: 5, batch: 592, loss: 0.21896, accu: 0.87500, speed: 9.62 step/s\r\n",
      "global step 4170, epoch: 5, batch: 602, loss: 0.22025, accu: 0.87500, speed: 9.54 step/s\r\n",
      "global step 4180, epoch: 5, batch: 612, loss: 0.30898, accu: 0.87891, speed: 9.60 step/s\r\n",
      "global step 4190, epoch: 5, batch: 622, loss: 0.40430, accu: 0.87187, speed: 8.95 step/s\r\n",
      "global step 4200, epoch: 5, batch: 632, loss: 0.36762, accu: 0.87313, speed: 8.74 step/s\r\n",
      "4200 eval loss: 0.75601, accuracy: 0.74481\r\n",
      "global step 4210, epoch: 5, batch: 642, loss: 0.39746, accu: 0.88750, speed: 1.19 step/s\r\n",
      "global step 4220, epoch: 5, batch: 652, loss: 0.30610, accu: 0.87500, speed: 9.39 step/s\r\n",
      "global step 4230, epoch: 5, batch: 662, loss: 0.34791, accu: 0.87500, speed: 9.60 step/s\r\n",
      "global step 4240, epoch: 5, batch: 672, loss: 0.34339, accu: 0.87422, speed: 9.59 step/s\r\n",
      "global step 4250, epoch: 5, batch: 682, loss: 0.29043, accu: 0.87438, speed: 9.63 step/s\r\n",
      "global step 4260, epoch: 5, batch: 692, loss: 0.25361, accu: 0.86979, speed: 9.13 step/s\r\n",
      "global step 4270, epoch: 5, batch: 702, loss: 0.40155, accu: 0.86652, speed: 9.15 step/s\r\n",
      "global step 4280, epoch: 5, batch: 712, loss: 0.43423, accu: 0.86406, speed: 8.94 step/s\r\n",
      "global step 4290, epoch: 5, batch: 722, loss: 0.27890, accu: 0.86424, speed: 9.55 step/s\r\n",
      "global step 4300, epoch: 5, batch: 732, loss: 0.16548, accu: 0.86219, speed: 9.51 step/s\r\n",
      "4300 eval loss: 0.69707, accuracy: 0.73892\r\n",
      "global step 4310, epoch: 5, batch: 742, loss: 0.41196, accu: 0.88438, speed: 1.17 step/s\r\n",
      "global step 4320, epoch: 5, batch: 752, loss: 0.46063, accu: 0.87031, speed: 9.56 step/s\r\n",
      "global step 4330, epoch: 5, batch: 762, loss: 0.49481, accu: 0.86875, speed: 9.54 step/s\r\n",
      "global step 4340, epoch: 5, batch: 772, loss: 0.25376, accu: 0.87109, speed: 9.54 step/s\r\n",
      "global step 4350, epoch: 5, batch: 782, loss: 0.30204, accu: 0.86625, speed: 9.57 step/s\r\n",
      "global step 4360, epoch: 5, batch: 792, loss: 0.38983, accu: 0.86667, speed: 9.54 step/s\r\n",
      "global step 4370, epoch: 5, batch: 802, loss: 0.32893, accu: 0.86071, speed: 9.54 step/s\r\n",
      "global step 4380, epoch: 5, batch: 812, loss: 0.23820, accu: 0.86094, speed: 9.52 step/s\r\n",
      "global step 4390, epoch: 5, batch: 822, loss: 0.27930, accu: 0.85833, speed: 9.53 step/s\r\n",
      "global step 4400, epoch: 5, batch: 832, loss: 0.43843, accu: 0.85938, speed: 9.45 step/s\r\n",
      "4400 eval loss: 0.67046, accuracy: 0.74173\r\n",
      "global step 4410, epoch: 5, batch: 842, loss: 0.36727, accu: 0.85000, speed: 1.17 step/s\r\n",
      "global step 4420, epoch: 5, batch: 852, loss: 0.24612, accu: 0.86406, speed: 9.36 step/s\r\n",
      "global step 4430, epoch: 5, batch: 862, loss: 0.27238, accu: 0.86979, speed: 9.58 step/s\r\n",
      "global step 4440, epoch: 5, batch: 872, loss: 0.18177, accu: 0.86719, speed: 9.51 step/s\r\n",
      "global step 4450, epoch: 5, batch: 882, loss: 0.35805, accu: 0.86875, speed: 9.54 step/s\r\n",
      "global step 4460, epoch: 5, batch: 892, loss: 0.12228, accu: 0.86792, speed: 9.68 step/s\r\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "import time\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "from eval import evaluate\n",
    "\n",
    "epochs = 5 # 训练轮次\n",
    "ckpt_dir = \"new_ernie_ckpt\" # 训练过程中保存模型参数的文件夹\n",
    "best_acc = 0    # 用于在训练过程中记录最好的模型性能\n",
    "best_step = 0   # 用于在训练过程中记录最好的模型性能对应的步骤数\n",
    "global_step = 0 # 迭代次数\n",
    "tic_train = time.time()\n",
    "for epoch in range(1, epochs + 1):\n",
    "    for step, batch in enumerate(train_data_loader, start=1):\n",
    "        input_ids, token_type_ids, labels = batch['input_ids'], batch['token_type_ids'], batch['labels']\n",
    "\n",
    "        # 计算模型输出、损失函数值、分类概率值、准确率\n",
    "        logits = model(input_ids, token_type_ids)   # 通过模型获取预测结果（logits）\n",
    "        loss = criterion(logits, labels)    # 使用交叉熵损失函数（criterion）计算预测结果（logits）和真实标签（labels）之间的损失。\n",
    "        probs = F.softmax(logits, axis=1)   # 使用softmax函数计算logits的概率分布，axis=1表示概率计算是在每个样本的输出类别上进行的。\n",
    "        correct = metric.compute(probs, labels) # 计算预测的准确性，metric.compute根据概率（probs）和真实标签（labels）来计算正确预测的数量。\n",
    "        metric.update(correct)              # 更新评估指标，将当前批次的正确预测数量添加到累积的评估中。\n",
    "        acc = metric.accumulate()           # 累积评估指标，计算到目前为止的总准确率。\n",
    "\n",
    "        # 每迭代10次，打印损失函数值、准确率、计算速度\n",
    "        global_step += 1\n",
    "        if global_step % 10 == 0:\n",
    "            print(\n",
    "                \"global step %d, epoch: %d, batch: %d, loss: %.5f, accu: %.5f, speed: %.2f step/s\"\n",
    "                % (global_step, epoch, step, loss, acc,\n",
    "                    10 / (time.time() - tic_train)))\n",
    "            tic_train = time.time()\n",
    "        \n",
    "        # 反向梯度回传，更新参数\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.clear_grad()\n",
    "\n",
    "        # 每迭代100次，评估当前训练的模型、保存当前模型参数和分词器的词表等\n",
    "        if global_step % 100 == 0:\n",
    "            save_dir = ckpt_dir\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            print(global_step, end=' ')\n",
    "            acc_eval = evaluate(model, criterion, metric, dev_data_loader)\n",
    "            if acc_eval > best_acc:\n",
    "                best_acc = acc_eval\n",
    "                best_step = global_step\n",
    "\n",
    "                model.save_pretrained(save_dir)\n",
    "                tokenizer.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:26:01.864885Z",
     "iopub.status.busy": "2024-03-27T14:26:01.864113Z",
     "iopub.status.idle": "2024-03-27T14:26:10.209385Z",
     "shell.execute_reply": "2024-03-27T14:26:10.208342Z",
     "shell.execute_reply.started": "2024-03-27T14:26:01.864841Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERNIE 3.0-Medium 在MCD的dev集表现 eval loss: 0.64031, accuracy: 0.75743\r\n"
     ]
    }
   ],
   "source": [
    "from eval import evaluate\n",
    "\n",
    "# 加载ERNIR 3.0最佳模型参数,本地训练模型\n",
    "params_path = 'new_ernie_ckpt/model_state.pdparams'#定义了预训练模型参数的路径\n",
    "state_dict = paddle.load(params_path)#这行代码使用PaddlePaddle的load函数从指定路径加载模型参数，并将其存储在state_dict变量中\n",
    "model.set_dict(state_dict)#将加载的模型参数设置到当前模型中\n",
    "\n",
    "# 也可以选择加载预先训练好的模型参数结果查看模型训练结果\n",
    "# model.set_dict(paddle.load('ernie_ckpt_trained/model_state.pdparams'))\n",
    "\n",
    "print('ERNIE 3.0-Medium 在MCD的dev集表现', end=' ')\n",
    "# 这行代码是在开发集（dev_data_loader）上评估模型的性能\n",
    "eval_acc = evaluate(model, criterion, metric, dev_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:27:24.127346Z",
     "iopub.status.busy": "2024-03-27T14:27:24.126717Z",
     "iopub.status.idle": "2024-03-27T14:27:24.133192Z",
     "shell.execute_reply": "2024-03-27T14:27:24.132298Z",
     "shell.execute_reply.started": "2024-03-27T14:27:24.127305Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 测试集数据预处理，利用分词器将文本转化为整数序列\n",
    "trans_func_test = functools.partial(preprocess_function, tokenizer=tokenizer, max_seq_length=128, is_test=True)\n",
    "test_ds_trans = test_ds.map(trans_func_test)\n",
    "\n",
    "# 进行采样组batch\n",
    "# 用于将不同长度的序列填充到批中数据的最大长度，然后将数据堆叠起来。这个函数需要一个分词器tokenizer作为输入\n",
    "collate_fn_test = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# 批量采样器用于从数据集中选择批量的数据。对于测试集，批大小被设置为32，数据不会被打乱。\n",
    "test_batch_sampler = BatchSampler(test_ds_trans, batch_size=32, shuffle=False)\n",
    "\n",
    "# 数据加载器用于在进行模型预测时批量加载数据。\n",
    "test_data_loader = DataLoader(dataset=test_ds_trans, batch_sampler=test_batch_sampler, collate_fn=collate_fn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:27:28.164410Z",
     "iopub.status.busy": "2024-03-27T14:27:28.163818Z",
     "iopub.status.idle": "2024-03-27T14:27:28.186971Z",
     "shell.execute_reply": "2024-03-27T14:27:28.186185Z",
     "shell.execute_reply.started": "2024-03-27T14:27:28.164372Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['消极']\r\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "from paddlenlp.transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 定义标签映射\n",
    "label_map = {0: '积极', 1: '中性', 2: '消极'}\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # 使用分词器处理输入文本\n",
    "    inputs = tokenizer(text, return_tensors='pd', truncation=True, max_length=128, pad_to_max_length=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "    token_type_ids = inputs['token_type_ids']\n",
    "\n",
    "    # 模型预测\n",
    "    model.eval()\n",
    "    with paddle.no_grad():\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        probs = F.softmax(logits, axis=1)\n",
    "        idx = paddle.argmax(probs, axis=1).numpy()\n",
    "        idx = idx.tolist()\n",
    "\n",
    "    # 返回预测的情感标签\n",
    "    return [label_map[i] for i in idx]\n",
    "\n",
    "# 测试\n",
    "text = \"今天那个负责出餐的女的，跟没吃饭似的，特别的慢腾腾，显示屏显示出餐，走过去问她，语气非常冷漠说等下，到了她叫号，过去也没出餐，过一会儿，出餐了，她跟没啥事似的，也不把餐端出来给我，我就问她好了吧，她才慢悠悠，是非常慢悠悠过去端给我。是不是身体有问题？身体有病就在家休息，别来上班，一点服务意识也没有，慢得跟个鬼似的。！\"\n",
    "print(predict_sentiment(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:28:51.750254Z",
     "iopub.status.busy": "2024-03-27T14:28:51.749585Z",
     "iopub.status.idle": "2024-03-27T14:28:59.381502Z",
     "shell.execute_reply": "2024-03-27T14:28:59.380438Z",
     "shell.execute_reply.started": "2024-03-27T14:28:51.750216Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 模型预测分类结果\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "#定义了一个标签映射\n",
    "label_map = {0: '积极', 1: '中性', 2: '消极'}\n",
    "results = []\n",
    "#这行代码将模型设置为评估模式。在评估模式下，模型的某些特性，如Dropout和BatchNorm，会被关闭，以确保模型的行为在预测时与训练时不同。\n",
    "model.eval()\n",
    "\n",
    "#循环的次数等于测试集的批次数量\n",
    "for batch in test_data_loader:\n",
    "    #这行代码从批次数据中提取出输入的token id（input_ids）和token类型id（token_type_ids）\n",
    "    input_ids, token_type_ids = batch['input_ids'], batch['token_type_ids']\n",
    "\n",
    "    #通过模型获取预测结果（logits）\n",
    "    logits = model(batch['input_ids'], batch['token_type_ids'])\n",
    "\n",
    "    #使用softmax函数计算logits的概率分布\n",
    "    probs = F.softmax(logits, axis=-1)\n",
    "\n",
    "    #这行代码找出每个样本预测概率最大的类别的索引\n",
    "    idx = paddle.argmax(probs, axis=1).numpy()\n",
    "\n",
    "    #这行代码将索引的numpy数组转换为列表\n",
    "    idx = idx.tolist()\n",
    "\n",
    "    #这行代码将数字标签转换为具体的类别\n",
    "    preds = [label_map[i] for i in idx]\n",
    "\n",
    "    #这行代码将预测的结果添加到results列表中\n",
    "    results.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-27T14:40:36.796576Z",
     "iopub.status.busy": "2024-03-27T14:40:36.795380Z",
     "iopub.status.idle": "2024-03-27T14:40:37.096692Z",
     "shell.execute_reply": "2024-03-27T14:40:37.095487Z",
     "shell.execute_reply.started": "2024-03-27T14:40:36.796523Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 存储预测结果  \n",
    "test = MyTestDataset('data/test.csv')\n",
    "test_ds = MapDataset(test,label_list=test.get_labels())\n",
    "\n",
    "res_dir = \"./results\"\n",
    "if not os.path.exists(res_dir):\n",
    "    os.makedirs(res_dir)\n",
    "with open(os.path.join(res_dir, \"MCD.tsv\"), 'w', encoding=\"utf8\") as f:\n",
    "    f.write(\"qid\\ttext\\tprediction\\n\")\n",
    "    for i, pred in enumerate(results):\n",
    "        f.write(str(test_ds[i]['qid'])+\"\\t\"+test_ds[i]['text']+\"\\t\"+str(pred)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T07:01:28.410670Z",
     "iopub.status.busy": "2024-04-07T07:01:28.409629Z",
     "iopub.status.idle": "2024-04-07T07:01:40.739541Z",
     "shell.execute_reply": "2024-04-07T07:01:40.738609Z",
     "shell.execute_reply.started": "2024-04-07T07:01:28.410629Z"
    },
    "scrolled": true,
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-07 15:01:31,798] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.modeling.ErnieForSequenceClassification'> to load 'new_ernie_ckpt'.\r\n",
      "[2024-04-07 15:01:40,591] [    INFO] - We are using <class 'paddlenlp.transformers.ernie.tokenizer.ErnieTokenizer'> to load 'new_ernie_ckpt'.\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['积极']\r\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "预测代码接口\n",
    "'''\n",
    "import paddle\n",
    "from paddlenlp.transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import paddle.nn.functional as F\n",
    "\n",
    "# 定义模型\n",
    "model_name = \"new_ernie_ckpt\"\n",
    "\n",
    "# 加载训练模型，指定分类的类别数为训练集的标签数量\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# 加载训练模型对应的分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 定义标签映射\n",
    "label_map = {0: '积极', 1: '中性', 2: '消极'}\n",
    "\n",
    "def predict_sentiment(text):\n",
    "    # 使用分词器处理输入文本\n",
    "    inputs = tokenizer(text, return_tensors='pd', truncation=True, max_length=128, pad_to_max_length=True)\n",
    "    input_ids = inputs['input_ids']\n",
    "    token_type_ids = inputs['token_type_ids']\n",
    "\n",
    "    # 模型预测\n",
    "    model.eval()\n",
    "    with paddle.no_grad():\n",
    "        logits = model(input_ids, token_type_ids)\n",
    "        probs = F.softmax(logits, axis=1)\n",
    "        idx = paddle.argmax(probs, axis=1).numpy()\n",
    "        idx = idx.tolist()\n",
    "\n",
    "    # 返回预测的情感标签\n",
    "    return [label_map[i] for i in idx]\n",
    "\n",
    "# 测试\n",
    "text = \"不知道吃什么，但是麦乐送也挺香的，免去了排队的时间\"\n",
    "print(predict_sentiment(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T03:49:20.428806Z",
     "iopub.status.busy": "2024-04-07T03:49:20.428240Z",
     "iopub.status.idle": "2024-04-07T03:49:20.520804Z",
     "shell.execute_reply": "2024-04-07T03:49:20.519846Z",
     "shell.execute_reply.started": "2024-04-07T03:49:20.428769Z"
    },
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['积极']\r\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "text = \"不知道吃什么，但是麦乐送也挺香的，免去了排队的时间\"\n",
    "print(predict_sentiment(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}